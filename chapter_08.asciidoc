Testing deployment using a staging site
---------------------------------------

It's time to deploy the first version of our site and make it public.  They say
that if you wait until you feel ready to ship, then you've waited too long.

Is our site usable?  Is it better than nothing? Can make lists on it? Yes, yes,
yes.

No, you can't log in yet.  No you can't mark tasks as completed.  But do we
really need any of that stuff? Not really -- and you can never be sure what
your users are 'actually' going to do with your site once they get their 
hands on it. We think our users want to use the site for to-do lists, but maybe
they actually want to use it to make "top 10 best fly-fishing spots" lists, for
which you don't need any kind of ``mark completed'' function. We won't know
until we put it out there.

In this chapter I'm going to go through and actually deploy my site to a real,
live web server.  

Now you might be tempted to skip this chapter -- there's lots of daunting stuff
in it, and maybe you think this isn't what you signed up for. But I 'strongly' 
urge you to give it a go.  This is one of the chapters I'm most pleased with,
and it's one that people often write to me saying they were really glad they
stuck through it. 

If you've never done a server deployment before, it will demistify a whole
world for you, and there's nothing like the feeling of seeing your site live on
the actual Internet. Give it a buzzword name like "DevOps" if that's what it
takes to convince you it's worth it ;-)

NOTE: Why not ping me a note once your site is live on the web? It'll give me
the warm and fuzzies.  obeythetestinggoat@gmail.com


TDD and the Danger Areas of deployment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Deploying a site to a live web server can be a tricky topic.  Oft-heard is the
forlorn cry -- '``but it works on my machine'''.

Some of the danger areas of deployment include:

- 'Static files' (CSS, JavaScript, images etc): web servers usually need
  special configuration for serving these
- The 'Database': there can be permissions and path issues, and we need to be
  careful about preserving data between deploys
- 'Dependencies': we need to make sure that the packages our software relies
  on are installed on the server, and have the correct versions

//TODO: this looks like it merges into the list above. fix styling somehow
[quote, 'https://twitter.com/DEVOPS_BORAT/status/192271992253190144[Devops Borat]']
______________________________________________________________
Is all fun and game until you are need of put it in production.
______________________________________________________________


But there are solutions to all of these.  In order:

- Using a 'staging site', on the same infrastructure as the production site,
  can help us test out our deployments and get things right before we go to the
  "real" site

- We can also 'run our functional tests against the staging site'. That will
  reassure us that we have the right code and packages on the server, and
  since we now have a "smoke test" for our site layout, we'll know that the CSS
  is loaded correctly.

- 'Virtualenvs' are a useful tool for managing packages and dependencies
  on a machine that might be running more than one Python application. 

- And finally, 'automation, automation, automation'.  By using an automated
  script to deploy new versions, and by using the same script to deploy to
  staging and production, we can reassure ourselves that staging is as much
  like live as possible.
footnote:[What I'm calling a "staging" server, some people would call a
"development" server, and some others would also like to distinguish
"pre-production" servers.  Whatever we call it, the point is to have somewhere
we can try our code out in an environment that's as similar as possible to the
real production server.] 

Over the next few pages I'm going to go through 'a' deployment procedure.  It 
isn't meant to be the 'perfect' deployment procedure, so please don't take
it as being best practice, or a recommendation -- it's meant to be an
illustration, to show the kinds of issues involved in deployment and where
testing fits in.

.Chapter overview
*******************************************************************************
There's lots of stuff in this chapter, so here's an overview to help you keep
your bearings:

* Adapt our FTs so they can run against a staging server.

* Spin up a server, install all the required software on it, and point our
  staging and live domains at it.

* Upload our code to the server using git.

* Try and get a quick & dirty version of our site running on the staging domain
  using the Django dev server.

* Learn how to use a virtualenv to manage our project's Python dependencies on
  the server.

* As we go, we'll keep running our FT, to tell us what's working and what's
  not.

* Move from our quick & dirty version to a production-ready configuration,
  using Gunicorn, upstart and domain sockets.

* Once we have a working config, we'll write a script to automate the process
  we've just been through manually, so that we can deploy our site
  automatically in future.

* Finally we'll use this script to deploy the production version of our site
  on its real domain.
*******************************************************************************


As always, start with a test
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Let's adapt our functional tests slightly so that it can be run against
a staging site. We'll do it by slightly hacking an argument that is normally
used to change the address which the test's temporary server gets run on:

[role="sourcecode"]
.functional_tests/tests.py (ch08l001)
[source,python]
----
import sys
[...]

class NewVisitorTest(LiveServerTestCase):

    @classmethod
    def setUpClass(cls): #<1>
        for arg in sys.argv: #<2>
            if 'liveserver' in arg: #<2>
                cls.server_url = 'http://' + arg.split('=')[1] #<3>
                return #<3>
        LiveServerTestCase.setUpClass()
        cls.server_url = cls.live_server_url

    @classmethod
    def tearDownClass(cls):
        if cls.server_url == cls.live_server_url:
            LiveServerTestCase.tearDownClass()


    def setUp(self):
        [...]
----

//TODO: use super()

OK, when I said slightly hacking, I meant seriously hacking. Do you remember I
said that `LiveServerTestCase` had certain limitations?  Well, one is that it
always assumes you want to use its own test server.  I still want to be able to
do that sometimes, but I also want to be able to selectively tell it not to
bother, and to use a real server instead.  

<1> `setUpClass` is a similar method to `setUp`, also provided by `unittest`,
    which is used to do test setup for the whole class, which means it only
    gets executed once, rather than before every test method. This is where
    `LiveServerTestCase` usually starts up its test server.  

<2> We look for the 'liveserver' command-line argument (which are found in
    `sys.argv`) 

<3> If we find it, we tell our test class to skip the normal `setUpClass`, and
    just store away our staging server URL in a variable called `server_url`
    instead.

This means we also need to change the three places we used to use
`self.live_server_url`:

[role="sourcecode"]
.functional_tests/tests.py (ch08l002)
[source,python]
----
    def test_can_start_a_list_and_retrieve_it_later(self):
        # Edith has heard about a cool new online to-do app. She goes
        # to check out its homepage
        self.browser.get(self.server_url)
        [...]
        # Francis visits the home page.  There is no sign of Edith's
        # list
        self.browser.get(self.server_url)
        [...]

    def test_layout_and_styling(self):
        # Edith goes to the home page
        self.browser.get(self.server_url)
----

We test that our little hack hasn't broken anything by running the functional
tests "normally":

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python3 manage.py test functional_tests*] 
[...]
Ran 2 tests in 8.544s

OK
----

And now we can try them against our staging server URL.  I'm hosting my staging
server at 'superlists-staging.ottg.eu':


[subs="specialcharacters,macros"]
----
$ pass:quotes[*python3 manage.py test functional_tests --liveserver=superlists-staging.ottg.eu*]
Creating test database for alias 'default'...
FF
======================================================================
FAIL: test_can_start_a_list_and_retrieve_it_later
(functional_tests.tests.NewVisitorTest)
 ---------------------------------------------------------------------
Traceback (most recent call last):
  File "/workspace/superlists/functional_tests/tests.py", line 42, in
test_can_start_a_list_and_retrieve_it_later
    self.assertIn('To-Do', self.browser.title)
AssertionError: 'To-Do' not found in 'Domain name registration | Domain names
| Web Hosting | 123-reg'

======================================================================
FAIL: test_layout_and_styling (functional_tests.tests.NewVisitorTest)
 ---------------------------------------------------------------------
Traceback (most recent call last):
  File
"/workspace/superlists/functional_tests/tests.py", line 118, in
test_layout_and_styling
    delta=3
AssertionError: 0.0 != 512 within 3 delta

 ---------------------------------------------------------------------
Ran 2 tests in 16.480s

FAILED (failures=2)
Destroying test database for alias 'default'...
----

You can see that both tests are failing, as expected, since I haven't
actually set up my staging site yet. In fact, you can see from the
first traceback that the test is actually ending up on the home page of
my domain registrar.

The FT seems to be testing the right things though, so let's commit.

[subs="specialcharacters,quotes"]
----
$ *git diff* # should show to functional_tests.py
$ *git commit -am "Hack FT runner to be able to test staging"*
----


Getting a domain name
~~~~~~~~~~~~~~~~~~~~~

We're going to need a couple of domain names at this point in the book -
they can both be subdomains of a single domain.  I'm going to use
'superlists.ottg.eu' and
'superlists-staging.ottg.eu'.
If you don't already own a domain, this is the time to register one! Again,
this is something I really want you to 'actually' do.  If you've never
registered a domain before, just pick any old registrar and buy a cheap one
-- it should only cost you $5 or so, and you can even find free ones too.
I promise seeing your site on a "real" web site will be a thrill :-)


Manually provisioning a server to host our site
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We can separate out "deployment" into two tasks:

- 'provisioning' a new server to be able to host the code
- 'deploying' a new version of the code to an existing server.

Some people like to use a brand new server for every deployment -- it's what we
do at PythonAnywhere.  That's only necessary for larger, more complex sites
though, or major changes to an existing site. For a simple site like ours, it
makes sense to separate the two tasks.  And, although we eventually want both
to be completely automated, we can probably live with a manual provisioning
system for now.

// TODO mention "immutable servers"?
// should be automated needs emphasis

As you go through this chapter, you should be aware that provisioning is
something that varies a lot, and that as a result there are few universal
best practices for deployment.  So, rather than trying to remember the 
specifics of what I'm doing here, you should be trying to understand the
rationale, so that you can apply the same kind of thinking in the
specific future circumstances you encounter.


Choosing where to host our site
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

There are loads of different solutions out there these days, but they broadly
fall into two camps:

- running your own (possibly virtual) server
- using a Platform-As-A-Service (PaaS) offering like Heroku, DotCloud,
  OpenShift or PythonAnywhere

Particularly for small sites, a PaaS offers a lot of advantages, and I would
definitely recommend looking into them.  We're not going to use a PaaS in this
book however, for several reasons.  Firstly, I have a conflict of interest, in
that I think PythonAnywhere is the best, but then again I would say that
because I work there.  Secondly, all the PaaS offerings are quite different,
and the procedures to deploy to each vary a lot -- learning about one doesn't
necessarily tell you about the others... And any one of them might change their
process radically, or simply go out of business by the time you get to read
this book.

Instead, we'll learn just a tiny bit of good old-fashioned server admin,
including SSH and web server config.  They're unlikely to ever go away, and
knowing a bit about them will get you some respect from all the grizzled
dinosaurs out there.

What I have done is to try and set up a server in such a way that it's a lot
like the environment you get from a PaaS, so you should be able to apply the
lessons we learn in the deployment section, no matter what provisioning
solution you choose.


Spinning up a server
^^^^^^^^^^^^^^^^^^^^

I'm not going to dictate how you do this -- whether you choose Amazon AWS,
Rackspace, Digital Ocean, your own server in your own data centre or a
Raspberry Pi in a cupboard behind the stairs, any solution should be fine, as
long as:

* Your server is running Ubuntu (13.04 or later)

* You have root access to it

* It's on the Internet, 

* You can SSH into it.  

I'm recommending Ubuntu as a distro, because it has Python 3.3, and it has some
specific ways of configuring Nginx which I'm going to make use of below.  If
you know what you're doing, you can probably get away with using something
else, but you're on your own.


TIP: Some people get to this chapter, and are tempted to skip the domain 
bit, and the "getting a real server" bit, and just use a VM on their own
PC.  Don't do this. It's 'not' the same, and you'll have more difficulty
following the instructions, which are complicated enough as it is.  If you're
worried about cost, dig around and you'll find free options for both.



User accounts, SSH and privileges
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In these instructions, I'm assuming that you have a non-root user account set
up that has "sudo" privileges, so whenever we need to do something that
requires root access, we use sudo, and I'm explicit about that in the various
instructions below. If you need to create a non-root user, here's how:

[role="skipme"]
[subs="specialcharacters,quotes"]
----
# these commands must be run as root
root@server:$ *useradd -m -s /bin/bash elspeth* # add user named elspeth 
# -m creates a home folder, -s sets elspeth to use bash by default
root@server:$ *usermod -a -G sudo elspeth* # add elspeth to the sudoers group
root@server:$ *passwd elspeth* # set password for elspeth
root@server:$ *su - elspeth* # switch-user to being elspeth!
elspeth@server:$ 
----

Name your own user whatever you like! I also recommend learning up how to use
private key authentication rather than passwords for SSH.  It's a matter of
taking the public key from your own PC, and appending it to
'~/.ssh/authorized_keys' in the user account on the server. You probably went
through a similar procedure if you signed up for Bitbucket or Github.

There are some good instructions
https://library.linode.com/security/ssh-keys[here]. (Note `ssh-keygen` 'is'
available as part of Git-Bash on Windows).

TIP: Look out for that `elspeth@server` in the command-line listings in this
chapter. The indicate commands that must be run on the server, as opposed to
commands you run on your own PC.


Installing Nginx
^^^^^^^^^^^^^^^^

We'll need a web server, and all the cool kids are using Nginx these days,
so we will too.  Having fought with Apache for many years, I can tell
you it's a blessed relief in terms of the readability of its config files,
if nothing else!

Installing Nginx on my server was a matter of doing an `apt-get`, and I could
then see the default Nginx "Hello World" screen:

.server command
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo apt-get install nginx*
elspeth@server:$ *sudo service nginx start*
----

(You may need to do an `apt-get update` and/or an `apt-get upgrade` first.)

.Nginx - It works!
image::images/nginx_it_worked.png[The default "Welcome to nginx!" page]


While we've got root access, let's make sure the server has the key
pieces of software we need at the system level: Python, Git, pip and virtualenv

.server commands
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo apt-get install git*
elspeth@server:$ *sudo apt-get install python3*
elspeth@server:$ *sudo apt-get install python3-pip*
elspeth@server:$ *sudo pip3 install virtualenv*
----


Configuring domains for staging and live
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Next, we don't want to be messing about with IP addresses all the time, so we
should point our staging and live domains to the server. At my registrar, the
control screens looked a bit like this:

.Domain setup
image::images/domain_setup.png[Registrar control screens for two domains]

In the DNS system, pointing a domain at a specific IP address is called an
"A-Record".  All registrars are slightly different, but a bit of clicking
around should get you to the right screen in yours...

To check this works, we can re-run our functional tests and see that their
failure messages have changed slightly

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python3 manage.py test functional_tests --liveserver=superlists-staging.ottg.eu*]
[...]
selenium.common.exceptions.NoSuchElementException: Message: 'Unable to locate
element: {"method":"tag name","selector":"input"}' ; Stacktrace:
[...]
AssertionError: 'To-Do' not found in 'Welcome to nginx!'
----

Progress!  


Deploying our code manually
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The next step is to get a copy of the staging site up and running, just
to check whether we can get Nginx and Django to talk to each other.  As
we do so, we're starting to do some of what you'd call "deployment", as
well as provisioning, so we should be thinking about how we can automate the
process, as we go.

NOTE: One way of telling the difference between provisioning and deployment is
that you tend to need root permissions for the former, but we don't for the
latter.

We need a directory for the source to live in.  Let's assume we have a home
folder for a non-root user, in my case it would be at '/home/harry' (this is
likely to be the setup on any shared hosting system, but you should always run
your web apps as a non-root user, in any case). I'm going to set up my
sites like this:

[role="skipme"]
----
/home/harry
├── sites
│   ├── www.live.my-website.com
│   │    ├── database
│   │    │     └── db.sqlite3
│   │    ├── source
│   │    │    ├── manage.py
│   │    │    ├── superlists
│   │    │    ├── etc...
│   │    │
│   │    ├── static
│   │    │    ├── base.css
│   │    │    ├── etc...
│   │    │
│   │    └── virtualenv
│   │         ├── lib
│   │         ├── etc...
│   │
│   ├── www.staging.my-website.com
│   │    ├── database
│   │    ├── etc...
----

Each site (staging, live, or any other website) has its own folder. Within that
we have a separate folder for the source code, the database, and the static
files.  The logic is that, while the source code might change from one version
of the site to the next, the database will stay the same.  The static folder
is in the same relative location, '../static', that we set up at the end of
the last chapter. Finally, the virtualenv gets its own subfolder too.  What's a
virtualenv, I hear you ask? We'll find out shortly.

NOTE: Do you need help creating a non-root user?  Try: `useradd -m
my-username` and then `passwd my-username`


Adjusting the database location
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

First let's change the location of our database in 'settings.py', and make sure
we can get that working on our local PC.  Using `os.path.abspath` prevents any
later confusions about the current working directory:

[role="sourcecode"]
.superlists/settings.py (ch08l003)
[source,python]
----
# Build paths inside the project like this: os.path.join(BASE_DIR, ...)
import os
BASE_DIR = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
[...]

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': os.path.join(BASE_DIR, '../database/db.sqlite3'),
    }
}
[...]

STATIC_ROOT = os.path.join(BASE_DIR, '../static')
----

Now let's try it locally:

[subs="specialcharacters,quotes"]
----
$ *mkdir ../database*
$ *python3 manage.py syncdb --noinput*
Creating tables ...
[...]
$ *ls ../database/*
db.sqlite3
----

That seems to work.  Let's commit it.

[subs="specialcharacters,quotes"]
----
$ *git diff* # should show changes in settings.py
$ *git commit -am "move sqlite database outside of main source tree"*
----

To get our code onto the server, we'll use git and go via one of the code
sharing sites.  If you haven't already, push your code up to GitHub, BitBucket
or similar.  They all have excellent instructions for beginners on how to
do that.

Here's some bash commands that will set this all up. If you're not familiar
with it, note the `export` command which lets me set up a "local variable"
in bash:

.server commands
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *export SITENAME=superlists-staging.ottg.eu*
elspeth@server:$ *mkdir -p \~/sites/$SITENAME*
elspeth@server:$ *mkdir \~/sites/$SITENAME/database*
elspeth@server:$ *mkdir \~/sites/$SITENAME/static*
elspeth@server:$ *mkdir \~/sites/$SITENAME/virtualenv*
# you should replace the URL in the next line with the URL for your own repo
elspeth@server:$ *git clone https://github.com/hjwp/book-example.git ~/sites/$SITENAME/source*
----

NOTE: A bash variable defined using `export` only lasts as long as that console
session. If you log out of the server and log back in again, you'll need to
re-define it. It's devious because bash won't error, it will just substitute
the empty string for the variable, which will lead to weird results...  If in
doubt, do a quick `echo $SITENAME`

Now we've got the site installed, let's just try running the dev server -- this
is a smoke test, to see if all the moving parts are connected:

.server commands
[subs="specialcharacters,quotes"]
----
elspeth@server:$ $ *cd ~/sites/$SITENAME/source*
$ *python3 manage.py runserver*
Traceback (most recent call last):
  File "manage.py", line 8, in <module>
    from django.core.management import execute_from_command_line
ImportError: No module named django.core.management
----

Ah. Django isn't installed on the server. 

Creating a virtualenv
^^^^^^^^^^^^^^^^^^^^^

We could install it at this point, but that would leave us with a problem:  if
we ever wanted to upgrade Django when a new version comes out, it would be
impossible to test the staging site with a different version from live.
Similarly, if there are other users on the server, we'd all be forced to use
the same version of Django.

The solution is a "virtualenv" -- a neat way of having different versions of
Python packages installed in different places, in their own "virtual
environments".

Let's try it out locally, on our own PC first:

[subs="specialcharacters,quotes"]
----
$ *pip3 install virtualenv*
----

We'll follow the same folder structure as we're planning for the server:

[subs="specialcharacters,quotes"]
----
$ *virtualenv --python=python3.3 ../virtualenv*
$ *ls ../virtualenv/*
bin  include  lib
----

NOTE: this folder structure will be slightly different on Windows, eg
bin=Scripts. Let me know if it's impossible to follow the instructions
as a result.
//TODO: run thru on windows, remove the "let me know"

That will create a folder at '../virtualenv' which will contain its own
copy of Python and `pip`, as well as a location to install Python packages
to.  It's a self-contained ``virtual'' Python environment.  To start using
it, we run a script called `activate`, which will change the system path
and the Python path in such a way as to use the virtualenv's executables
and packages:

[subs="specialcharacters,quotes"]
----
$ *source ../virtualenv/bin/activate*
(virtualenv)$ *python3 manage.py test lists*
[...]
ImportError: No module named \'django'
----

NOTE: it's not required, but you might want to look into a tool called
`virtualenvwrapper` for managing virtualenvs on your own PC.

That will show an `ImportError: No module named django` because Django isn't
installed inside the virtualenv.  So, we can install it, and see that it
ends up inside the virtualenv's 'site-packages' folder:

[subs="specialcharacters,quotes"]
----
(virtualenv)$ *pip install django*
[...]
Successfully installed django
Cleaning up...
(virtualenv)$ *python3 manage.py test lists*
[...]
OK
$ *ls ../virtualenv/lib/python3.3/site-packages/*
django                       pip                     setuptools
Django-1.6-py3.3.egg-info  pip-1.4.1-py3.3.egg-info  setuptools-0.9.8-py3.3.egg-info
easy_install.py              pkg_resources.py
_markerlib                   __pycache__
----

To "save" the list of packages we need in our virtualenv, and be able to 
re-create it later, we create a 'requirements.txt' file, using `pip freeze`,
and add that to our repository:

[subs="specialcharacters,quotes"]
----
(virtualenv)$ *pip freeze > requirements.txt*
(virtualenv)$ *deactivate*
$ *cat requirements.txt*
Django==1.6
$ *git add requirements.txt*
$ *git commit -m"Add requirements.txt for virtualenv"*
----

And now we do a `git push` to send our updates up to our code-sharing site

[subs="specialcharacters,quotes"]
----
$ *git push* 
----

And we can pull those changes down to the server, create a virtualenv on 
the server, and use 'requirements.txt' along with `pip install -r` to 
make the server virtualenv just like our local one:

.server commands
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *git pull*
elspeth@server:$ *virtualenv --python=python3.3 ../virtualenv/*
elspeth@server:$ *source ../virtualenv/bin/activate*
(virtualenv)$ *pip install -r requirements.txt*
Downloading/unpacking Django==1.6 (from -r requirements.txt (line 1))
[...]
Successfully installed Django
Cleaning up...
(virtualenv)$ *python3 manage.py runserver*
Validating models...
0 errors found
[...]
----

That looks like it worked.  

Simple nginx configuration
^^^^^^^^^^^^^^^^^^^^^^^^^^

Let's now go and create an nginx config file to tell it to send requests for
our staging site along to Django. A minimal config looks like this:


[role="sourcecode"]
.server: /etc/nginx/sites-available/superlists-staging.ottg.eu
[source,nginx]
----
server {
    listen 80;
    server_name superlists-staging.ottg.eu;

    location / {
        proxy_pass http://localhost:8000;
    }
}
----

This config says it will only work for our staging domain, and will "proxy"
all requests to the local port 8000 where it expects to find Django
waiting to respond to requests.

I saved
footnote:[not sure how to edit a file on the server?  There's always vi, which
I'll keep encouraging you to learn a bit of. Alternatively, try the relatively
beginner-friendly nano.]
this to a file called 'superlists-staging.ottg.eu'
inside '/etc/nginx/sites-available' folder, and then added it to the enabled
sites for the server by creating a symlink to it:

.server command
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo ln -s ../sites-available/$SITENAME /etc/nginx/sites-enabled/$SITENAME*
----


That's the Debian/Ubuntu preferred way of saving nginx configurations -- 
the real config file in 'sites-available', and a symlink in 'sites-enabled',
the idea is that it makes it easier to switch sites on or off.

NOTE: I also had to edit '/etc/nginx/nginx.conf' and uncomment a line saying
`server_names_hash_bucket_size 64;` to get my long domain name to work.  You 
may not have this problem; Nginx will warn you when you do a `reload` if it has
any trouble with its config files.

We also may as well remove the default "Welcome to nginx" config, to avoid any
confusion:

.server command
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo rm /etc/nginx/sites-enabled/default*
elspeth@server:$ *sudo reboot*
----

(The reboot is there to avoid a strange issue I came across whereby nginx 
would keep serving the default page on the first hit. There always seems
to be some voodoo in server config!)

And now to test it:

.server commands
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo service nginx reload*
elspeth@server:$ *source ../virtualenv/bin/activate*
(virtualenv)$ *python3 manage.py runserver*
----

A quick visual inspection confirms -- the site is up!

.Staging site is up!
image::images/staging_is_up.png[The front page of the site, at least, is up]

Let's see what our functional tests say:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python3 manage.py test functional_tests --liveserver=superlists-staging.ottg.eu*]
[...]
selenium.common.exceptions.NoSuchElementException: Message: 'Unable to locate
[...]
AssertionError: 0.0 != 512 within 3 delta
----

The tests are failing as soon as they try and submit a new item, because we
haven't set up the database. You'll probably have spotted the yellow Django
debug telling us as much as the tests went through, or if you tried it
manually.


.But the database isn't
image::images/staging_database_error.png[Django DEBUG page showing database error]


Let's set up the database then.


Creating the database with syncdb
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We run `syncdb` using the `--noinput` argument to suppress the two little "are
you sure" prompts.  Press Ctrl+C to interrup the current `runserver`.

.server commands
[subs="specialcharacters,quotes"]
----
(virtualenv)$ *python3 manage.py syncdb --noinput*
Creating tables ...
[...]
(virtualenv)$ *ls ../database/*
db.sqlite3
(virtualenv)$ *python3 manage.py runserver*
----

Let's try the FTs again:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python3 manage.py test functional_tests --liveserver=superlists-staging.ottg.eu*]
Creating test database for alias 'default'...
..
 ---------------------------------------------------------------------
Ran 2 tests in 10.718s

OK
Destroying test database for alias 'default'...
----

NOTE: if you see a "502 - Bad Gateway", it's probably because you forgot to
restart the dev server with `manage.py runserver` after the `syncdb`

Progress!  We're at least reassured that some of the piping works, but we
really can't be using the Django dev. server in production.  We also can't be
relying on manually starting it up with `runserver`.


Switching to Gunicorn
^^^^^^^^^^^^^^^^^^^^^

Do you know why the Django mascot is a pony?  The story is that Django
comes with so many things you want -- an ORM, all sorts of middleware,
the admin site -- that: "what else do you want, a pony?". Well, Gunicorn stands
for "Green Unicorn", which I guess is what you'd want next if you already
had a pony...

.server command
[subs="specialcharacters,quotes"]
----
(virtualenv)$ *pip install gunicorn*
----

Gunicorn will need to know a path to a WSGI server, which is usually
a function called `application`.  Django provides one in 'superlists/wsgi.py'.

We can try that out, and check that all the virtualenv magic works too, by
'deactivating' the virtualenv and seeing if we can 'still' serve our app using
the `gunicorn` executable that pip just put in there for us:


.server commands
[subs="specialcharacters,quotes"]
----
(virtualenv)$ *which gunicorn*
/home/harry/sites/superlists-staging.ottg.eu/virtualenv/bin/gunicorn
(virtualenv)$ deactivate
$ *../virtualenv/bin/gunicorn superlists.wsgi:application*
2013-05-27 16:22:01 [10592] [INFO] Starting gunicorn 0.18.0
2013-05-27 16:22:01 [10592] [INFO] Listening at: http://127.0.0.1:8000 (10592)
[...]
----

If you now take a look at the site, you'll find the CSS is all broken:

.Broken CSS
image::images/staging_with_broken_css.png[The site is up, but CSS is broken]

And if we run the functional tests, you'll see they confirm that something
is wrong. The test for adding list items passes happily, but the test for 
layout + styling fails.  Good job tests!

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python3 manage.py test functional_tests --liveserver=superlists-staging.ottg.eu*]
[...]
AssertionError: 125 != 497 within 3 delta
FAILED (failures=1)
----

The reason that the CSS is broken is that although the Django dev server will
serve static files magically for you, Gunicorn doesn't.  Now is the time to
tell Nginx to do it instead.


Getting Nginx to serve static files
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

First we run `collectstatic` to copy all the static files to a folder where 
Nginx can find them:

.server commands
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *../virtualenv/bin/python3 manage.py collectstatic --noinput*
elspeth@server:$ *ls ../static/*
base.css  bootstrap
----

Note that, again, instead of using the virtualenv `activate` command, we 
can use the direct path to the virtualenv's copy of Python instead.

Now we tell Nginx to start serving those static files for us:

[role="sourcecode"]
.server: /etc/nginx/sites-available/superlists-staging.ottg.eu
[source,nginx]
----
server {
    listen 80;
    server_name superlists-staging.ottg.eu;

    location /static {
        alias /home/harry/sites/superlists-staging.ottg.eu/static;
    }

    location / {
        proxy_pass http://localhost:8000;
    }
}
----

Reload nginx and restart gunicorn...

.server commands
[subs="specialcharacters,quotes"]
----
$ *sudo service nginx reload*
$ *../virtualenv/bin/gunicorn superlists.wsgi:application*
----

And if we take another look at the site, things are looking much healthier. We
can re-run our FTs:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python3 manage.py test functional_tests --liveserver=superlists-staging.ottg.eu*]
Creating test database for alias 'default'...
..
 ---------------------------------------------------------------------
Ran 2 tests in 10.718s

OK
Destroying test database for alias 'default'...
----


Switching to using Unix sockets
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When we want to serve both staging and live, we can't have both servers trying
to use port 8000.  We could decide to allocate different ports, but that's a
bit arbitrary, and it would be dangerously easy to get it wrong and start
the staging server on the live port, or vice versa.

A better solution is to use unix domain sockets -- they're like files on disk,
but can be used by nginx and gunicorn to talk to each other.  We'll put our
sockets in '/tmp'.  Let's change the proxy settings in nginx:

[role="sourcecode"]
.server: /etc/nginx/sites-available/superlists-staging.ottg.eu
[source,nginx]
----
[...]
    location / {
        proxy_set_header Host $host;
        proxy_pass http://unix:/tmp/superlists-staging.ottg.eu.socket;
    }
}
----

`proxy_set_header` is to make sure Gunicorn and Django know what domain
it's running on.  We need that for the `ALLOWED_HOSTS` security feature, which 
we're about to switch on.

Now we restart Gunicorn, but this time telling it to listen on a socket instead
of on the default port:

.server commands
[subs="specialcharacters,quotes"]
----
$ *sudo service nginx reload*
$ *../virtualenv/bin/gunicorn --bind \
    unix:/tmp/superlists-staging.ottg.eu.socket superlists.wsgi:application*
----


And again, we re-run the functional test again, to make sure things still pass.

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python3 manage.py test functional_tests --liveserver=superlists-staging.ottg.eu*]
OK
----

A couple more steps!


Switching DEBUG to False and setting ALLOWED_HOSTS
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Django's DEBUG mode is all very well for hacking about on your own server, but
leaving those pages full of tracebacks available
https://docs.djangoproject.com/en/1.6/ref/settings/#debug[isn't secure].

You'll find the `DEBUG` setting at the top of 'settings.py'. When we set this
to `False`, we also need to set another setting called `ALLOWED_HOSTS`. This
was
https://docs.djangoproject.com/en/1.6/ref/settings/#std:setting-ALLOWED_HOSTS[added
as a security feature] in Django 1.5.  Unfortunately it doesn't have a helpful
comment in the default 'settings.py', but we can add one ourselves.  Do this on
the server:

[role="sourcecode"]
.server: superlists/settings.py
[source,python]
----
# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = False

TEMPLATE_DEBUG = DEBUG

# Needed when DEBUG=False
ALLOWED_HOSTS = ['superlists-staging.ottg.eu']
[...]
----

And, once again, we restart Gunicorn and run the FT to check things still work.

NOTE: Don't commit these changes on the server. At the moment this is just a 
hack to get things working, not a change we want to keep in our repo. In
general, to keep things simple, I'm only going to do git commits from the local
PC, using `git push` and `git pull` when I need to sync them up to the server.



Using upstart to make sure gunicorn starts on boot
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Our final step is to make sure that the server starts up gunicorn automatically
on boot, and reloads it automatically if it crashes.  On Ubuntu, the way to do
this is using upstart.

[role="sourcecode"]
.server: /etc/init/gunicorn-superlists-staging.ottg.eu.conf
[source,bash]
----
description "Gunicorn server for superlists-staging.ottg.eu"

start on net-device-up
stop on shutdown

respawn

chdir /home/harry/sites/superlists-staging.ottg.eu/source
exec ../virtualenv/bin/gunicorn \
    --bind unix:/tmp/superlists-staging.ottg.eu.socket \
    superlists.wsgi:application
----

//TODO: setuid to something.

// TODO: log files? straight away?

Upstart is joyously simple to configure (especially if you've ever had the
pleasure of writing an `init.d` script), and is fairly self-explanatory.
The `start on net-device-up` makes sure Gunicorn only runs once the server
has connected up to the internet.  `respawn` will restart Gunicorn
automatically if it crashes, and `chdir` sets the working directory

Upstart scripts live in '/etc/init', and their names must end in '.conf'. 

Now we can start gunicorn with

.server commands
[subs="specialcharacters,quotes"]
----
sudo start gunicorn-superlists-staging.ottg.eu
----


And we can re-run the FTs to see that everything still works. You can even test
that the site comes back up if you reboot the server!


Saving our changes:  adding gunicorn to our requirements.txt
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Back in the *local* copy of your repo, we should add gunicorn to the list
of packages we need in our virtualenvs:

[subs="specialcharacters,quotes"]
----
$ *source ../virtualenv/bin/activate*
(virtualenv)$ pip install gunicorn
(virtualenv)$ *pip freeze > requirements.txt*
(virtualenv)$ deactivate
$ *git commit -am "Add gunicorn to virtualenv requirements"*
$ *git push* 
----

NOTE: On Windows, at the time of writing, gunicorn would pip install quite
happily, but it wouldn't actually work if you tried to use it.  Thankfully
we only ever run it on the server, so that's not a problem. And, Windows
support is
http://stackoverflow.com/questions/11087682/does-gunicorn-run-on-windows[being
discussed]...



Automating:
~~~~~~~~~~~


Let's re-cap on our provisioning and deployment procedures

Provisioning:

* assume we have a user account & home folder
* apt-get nginx git python-pip
* pip install virtualenv
* add nginx config for virtual host
* add upstart job for gunicorn


Deployment

* create directory structure in '~/sites'
* pull down source code into folder named source
* start virtualenv in '../virtualenv'
* pip install -r requirements.txt
* syncdb for database
* collectstatic for static files
* set DEBUG = False and ALLOWED_HOSTS in settings.py
* restart gunicorn job
* run FTs to check everything works


Assuming we're not ready to entirely automate our provisioning process, how
should we save the results of our investigation so far?  I would say that 
the nginx and upstart config files should probably be saved somewhere, in
a way that makes it easy to re-use them later.  Let's save them in a new
subfolder in our repo:


[subs="specialcharacters,quotes"]
----
$ *mkdir deploy_tools*
----


[role="sourcecode"]
.deploy_tools/nginx.template.conf
[source,nginx]
----
server {
    listen 80;
    server_name SITENAME;

    location /static {
        alias /home/harry/sites/SITENAME/static;
    }

    location / {
        proxy_set_header Host $host;
        proxy_pass http://unix:/tmp/SITENAME.socket;
    }
}
----


[role="sourcecode"]
.deploy_tools/gunicorn-upstart.template.conf
[source,bash]
----
description "Gunicorn server for SITENAME"

start on net-device-up
stop on shutdown

respawn

chdir /home/harry/sites/SITENAME/source
exec ../virtualenv/bin/gunicorn \
    --bind unix:/tmp/SITENAME.socket \
    superlists.wsgi:application
----

Then it's easy for us to use those two files to generate
a new site, by doing a find & replace on  `SITENAME`

For the rest, just keeping a few notes is OK. Why not keep
them in a file in the repo too?


[role="sourcecode"]
.deploy_tools/provisioning_notes.md
[source,rst]
----
Provisioning a new site
=======================

## Required packages:

* nginx
* Python 3
* Git
* pip
* virtualenv

eg, on Ubuntu:

    sudo apt-get install nginx git python3 python3-pip
    sudo pip3 install virtualenv

## Nginx Virtual Host config

* see nginx.template.conf
* replace SITENAME with, eg, staging.my-domain.com

## Upstart Job

* see gunicorn-upstart.template.conf
* replace SITENAME with, eg, staging.my-domain.com

## Folder structure:
Assume we have a user account at /home/username

/home/username
└── sites
    └── SITENAME
         ├── database
         ├── source
         ├── static
         └── virtualenv
----

We can do a commit for those:

[subs="specialcharacters,quotes"]
----
$ *git add deploy_tools*
$ *git status* # see three new files
$ *git commit -m "Notes and template config files for provisioning"*
----

Our source tree will now look something like this:

----
$ tree -I __pycache__
.
├── deploy_tools
│   ├── gunicorn-upstart.template.conf
│   ├── nginx.template.conf
│   └── provisioning_notes.md
├── functional_tests
│   ├── __init__.py
│   ├── [...]
├── lists
│   ├── __init__.py
│   ├── models.py
│   ├── static
│   │   ├── base.css
│   │   ├── [...]
│   ├── templates
│   │   ├── base.html
│   │   ├── [...]
├── manage.py
├── requirements.txt
└── superlists
    ├── [...]
----


Automating deployment with fabric
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Fabric is a tool which lets you automate commands that you want to run on
servers. You can install fabric system-wide -- it's not part of the core
functionality of our site, so it doesn't need to go into our virtualenv and
'requirements.txt'. So, on your local PC:

[subs="specialcharacters,quotes"]
----
$ *pip-2.7 install fabric*
----

WARNING: at the time of writing, Fabric had not been ported to Python 3, so
we have to use the Python 2 version.  Thankfully, the fabric code is totally
separate from the rest of our codebase, so it's not a problem.

.Installing Fabric on Windows.
*******************************************************************************
Fabric depends on pycrypto, which is a package that needs compiling. Compiling
on Windows is a rather fraught process; it's often quicker to try and
get hold of precompiled binaries put out there by some kindly soul.  In this
case the excellent Michael Foord has provided some windows binaries:

http://www.voidspace.org.uk/python/modules.shtml#pycrypto

(Don't forget to giggle at the mention of absurd US munitions export controls.)

So the instructions, for Windows, are:
- download and install pycrypto from the url above
- then pip install fabric.

Another amazing source of precompiled Python packages for Windows is maintained
by Christoph Gohlke at:

http://www.lfd.uci.edu/~gohlke/pythonlibs/

*******************************************************************************

The usual setup is to have a file called 'fabfile.py', which will
contain one or more functions that can later be invoked from a command-line
tool called `fab`, like this:

----
fab function_name,host=SERVER_ADDRESS
----

That will invoke the function called function_name, passing in a connection
to the server at SERVER_ADDRESS.  There are many other options for specifying
usernames and passwords, which you can find out about using `fab --help`

The best way to see how it works is with an example.
https://en.wikipedia.org/wiki/Blue_Peter#Content[Here's one I made earlier],
automating all the deployment steps we've been going through.  The main
function is called `deploy`, that's the one we'll invoke from the command-line.
It uses several helper functions.  `env.host` will contain the server address
that we've passed in.


[role="sourcecode"]
.deploy_tools/fabfile.py
[source,python]
----
from fabric.contrib.files import append, exists, sed
from fabric.api import env, local, run
import random

REPO_URL = 'https://github.com/hjwp/book-example.git' #<1>
SITES_FOLDER = '/home/harry/sites'

def deploy():
    _create_directory_structure_if_necessary(env.host) #<2>
    source_folder = '%s/%s/source' % (SITES_FOLDER, env.host)
    _get_latest_source(source_folder)
    _update_settings(source_folder, env.host)
    _update_virtualenv(source_folder)
    _update_static_files(source_folder)
    _update_database(source_folder)
----

<1> You'll want to update the `REPO_URL` variable with the URL of your
    own git repo on its code sharing site

<2> `env.host` will contain the address of the server we've specified at the 
    command-line, eg 'superlists.ottg.eu'.

Hopefully each of those helper functions have fairly self-descriptive names.
Because any function in a fabfile can theoretically be invoked from the
command- line, I've used the convention of a leading underscore to indicate
that they're not meant to be part of the "public API" of the fabfile. Here
they are in chronological order.

Here's how we build our directory structure, in a way that doesn't fall 
down if it already exists:

[role="sourcecode"]
.deploy_tools/fabfile.py
[source,python]
----
def _create_directory_structure_if_necessary(site_name):
    for subfolder in ('database', 'static', 'virtualenv', 'source'):
        run('mkdir -p %s/%s/%s' % (SITES_FOLDER, site_name, subfolder)) #<1><2>
----

<1> `run` is the most common fabric command.  It says "run this shell command
    on the server".

<2> `mkdir -p` is a useful flavor of `mkdir`, which is better than mkdir in two
    ways: it can create directories several levels deep, and it only creates
    them if necessary.  So, `mkdir -p /tmp/foo/bar` will create the directory
    'bar' but also its parent directory 'foo' if it needs to.  It also won't
    complain if 'bar' already exists.
footnote:[If you're wondering why we're building up paths manually with `%s` 
instead of the `os.path.join` command we saw earlier, it's because path.join
will use backslashes if you run the script from Windows, but we definitely 
want forward slashes on the server]


Next we want to pull down our source code:

[role="sourcecode"]
.deploy_tools/fabfile.py
[source,python]
----
def _get_latest_source(source_folder):
    if exists(source_folder + '/.git'): #<1>
        run('cd %s && git fetch' % (source_folder,)) #<2><3>
    else:
        run('git clone %s %s' % (REPO_URL, source_folder)) #<4>
    current_commit = local("git log -n 1 --format=%H", capture=True) #<5>
    run('cd %s && git reset --hard %s' % (source_folder, current_commit)) #<6>
----

<1> `exists` checks whether a directory or file already exists on the server.
    We look for the '.git' hidden folder to check whether the repo has already
    been cloned in that folder.

<2> Many commands start with a `cd` in order to set the current working
    directory. Fabric doesn't have any state, so it doesn't remember what
    directory you're in from one `run` to the next.
    footnote:[there is a fabric "cd" command, but I figured it was one thing
    too many to add in this chapter]

<3> `git fetch` inside an existing repository pulls down all the latest commits
    from the web

<4> Alternatively we use `git clone` with the repo URL to bring down a fresh
    source tree.

<5> Fabric's `local` command runs a command on your local machine -- it's just
    a wrapper around `subprocess.Popen` really, but it's quite convenient.
    Here we capture the output from that `git log` invocation to get the hash
    of the current commit that's in your local tree.  That means the server
    will end up with whatever code is currently checked out on your machine
    (as long as you've pushed it up to the server).

<6> We `reset --hard` to that commit, which will blow away any current changes
    in the server's code directory.  

NOTE: For this script to work, the current commit that's in your local working
tree needs to be up on the VCS code sharing site, so that the server can pull
it down and reset to it.  So if you see an errors saying `Could not parse
object`, try doing a `git push`.


Next we update our settings file, to set the `ALLOWED_HOSTS` and `DEBUG`, and
to create a new secret key:

[role="sourcecode"]
.deploy_tools/fabfile.py
[source,python]
----
def _update_settings(source_folder, site_name):
    settings_path = source_folder + '/superlists/settings.py'
    sed(settings_path, "DEBUG = True", "DEBUG = False") #<1>
    sed(settings_path,
        'ALLOWED_HOSTS =.+$',
        'ALLOWED_HOSTS = ["%s"]' % (site_name,) #<2>
    )
    secret_key_file = source_folder + '/superlists/secret_key.py'
    if not exists(secret_key_file): #<3>
        chars = 'abcdefghijklmnopqrstuvwxyz0123456789!@#$%^&*(-_=+)'
        key = ''.join(random.SystemRandom().choice(chars) for _ in range(50))
        append(secret_key_file, "SECRET_KEY = '%s'" % (key,))
    append(settings_path, '\nfrom .secret_key import SECRET_KEY') #<4>
----

<1> The fabric `sed` command does a string substitution in a file, here it's
    changing DEBUG from True to False.  

<2> And here it is adjust `ALLOWED_HOSTS`, using a regex to match 
    bother if the line is already there).

<3> Django uses `SECRET_KEY` for some if its crypto -- cookies and CSRF
    protection. It's good practice to make sure the secret key on the server
    is different from the one in your (possibly public) source code repo. This
    code will generate a new key to import into settings, if there isn't one
    there already (once you have a secret key, it should stay the same between
    deploys).  More info in the
    https://docs.djangoproject.com/en/1.6/topics/signing/[Django docs]

<4> `append` just adds a line to the end of a file (it's clever enough not to
    bother if the line is already there, but not clever enough to automatically
    add a newline if the file doesn't end in one.  hence the back-n).
    
NOTE: Other people suggest using environment variables to set things like 
    secret keys; you should use whatever you feel is most secure in your
    environment.

//TODO: this is a first use of a relative import, which I only explain in 
// next chapter

Next we create or update the virtualenv:

[role="sourcecode"]
.deploy_tools/fabfile.py
[source,python]
----
def _update_virtualenv(source_folder):
    virtualenv_folder = source_folder + '/../virtualenv'
    if not exists(virtualenv_folder + '/bin/pip'): #<1>
        run('virtualenv --python=python3.3 %s' % (virtualenv_folder,))
    run('%s/bin/pip install -r %s/requirements.txt' % ( #<2>
            virtualenv_folder, source_folder
    ))
----


<1> We look inside the virtualenv folder for the `pip` executable as a way of
    checking whether it already exists.

<2> Then we use `pip install -r` like we did earlier.


Updating static files is a single command:

[role="sourcecode"]
.deploy_tools/fabfile.py
[source,python]
----
def _update_static_files(source_folder):
    run('cd %s && ../virtualenv/bin/python3 manage.py collectstatic --noinput' % ( # <1>
        source_folder,
    ))
----

<1> We use the virtualenv binaries folder whenever we need to run a Django 
    'manage.py' command, to make sure we get the virtualenv version of django,
    not the system one.

Finally, we update the database with `syncdb`:

[role="sourcecode"]
.deploy_tools/fabfile.py
[source,python]
----
def _update_database(source_folder):
    run('cd %s && ../virtualenv/bin/python3 manage.py syncdb --noinput' % (
        source_folder,
    ))
----


We can try this command out on our existing staging site -- the script should
work for an existing site as well as for a new one.  If you like words with
Latin roots, you might describe it as idempotent, which means it does nothing
if run twice...

[subs="specialcharacters,macros"]
----
$ pass:quotes[*cd deploy_tools*]
$ pass:quotes[*fab deploy:host=harry@superlists-staging.ottg.eu*]

[superlists-staging.ottg.eu] Executing task 'deploy'
[superlists-staging.ottg.eu] run: mkdir -p /home/harry/sites/superlists-staging.ottg.eu
[superlists-staging.ottg.eu] run: mkdir -p /home/harry/sites/superlists-staging.ottg.eu/database
[superlists-staging.ottg.eu] run: mkdir -p /home/harry/sites/superlists-staging.ottg.eu/static
[superlists-staging.ottg.eu] run: mkdir -p /home/harry/sites/superlists-staging.ottg.eu/virtualenv
[superlists-staging.ottg.eu] run: mkdir -p /home/harry/sites/superlists-staging.ottg.eu/source
[superlists-staging.ottg.eu] run: cd /home/harry/sites/superlists-staging.ottg.eu/source && git fetch
[localhost] local: git log -n 1 --format=%H
[superlists-staging.ottg.eu] run: cd /home/harry/sites/superlists-staging.ottg.eu/source && git reset --hard 85a6c87d5d93c25b265ad0e712f402c76e2e01c3
[superlists-staging.ottg.eu] out: HEAD is now at 85a6c87 Add a fabfile for automated deploys
[superlists-staging.ottg.eu] out: 

[superlists-staging.ottg.eu] run: sed -i.bak -r -e 's/DEBUG = True/DEBUG = False/g' "$(echo /home/harry/sites/superlists-staging.ottg.eu/source/superlists/settings.py)"
[superlists-staging.ottg.eu] run: echo 'ALLOWED_HOSTS = ["superlists-staging.ottg.eu"]' >> "$(echo /home/harry/sites/superlists-staging.ottg.eu/source/superlists/settings.py)"
[superlists-staging.ottg.eu] run: echo 'SECRET_KEY = '\\''4p2u8fi6)bltep(6nd_3tt9r41skhr%ttyjatf4+n#)jr=vd-q'\\''' >> "$(echo /home/harry/sites/superlists-staging.ottg.eu/source/superlists/secret_key.py)"
[superlists-staging.ottg.eu] run: echo 'from .secret_key import SECRET_KEY' >> "$(echo /home/harry/sites/superlists-staging.ottg.eu/source/superlists/settings.py)"

[superlists-staging.ottg.eu] run: /home/harry/sites/superlists-staging.ottg.eu/source/../virtualenv/bin/pip install -r /home/harry/sites/superlists-staging.ottg.eu/source/requirements.txt
[superlists-staging.ottg.eu] out: Requirement already satisfied (use --upgrade to upgrade): Django==1.6 in ./sites/superlists-staging.ottg.eu/virtualenv/lib/python3.3/site-packages (from -r /home/harry/sites/superlists-staging.ottg.eu/source/requirements.txt (line 1))
[superlists-staging.ottg.eu] out: Requirement already satisfied (use --upgrade to upgrade): gunicorn==17.5 in ./sites/superlists-staging.ottg.eu/virtualenv/lib/python3.3/site-packages (from -r /home/harry/sites/superlists-staging.ottg.eu/source/requirements.txt (line 2))
[superlists-staging.ottg.eu] out: Cleaning up...
[superlists-staging.ottg.eu] out: 

[superlists-staging.ottg.eu] run: cd /home/harry/sites/superlists-staging.ottg.eu/source && ../virtualenv/bin/python3 manage.py collectstatic --noinput
[superlists-staging.ottg.eu] out: 
[superlists-staging.ottg.eu] out: 0 static files copied, 11 unmodified.
[superlists-staging.ottg.eu] out: 

[superlists-staging.ottg.eu] run: cd /home/harry/sites/superlists-staging.ottg.eu/source && ../virtualenv/bin/python3 manage.py syncdb --noinput
[superlists-staging.ottg.eu] out: Creating tables ...
[superlists-staging.ottg.eu] out: Installing custom SQL ...
[superlists-staging.ottg.eu] out: Installing indexes ...
[superlists-staging.ottg.eu] out: Installed 0 object(s) from 0 fixture(s)
[superlists-staging.ottg.eu] out: 
Done.
Disconnecting from superlists-staging.ottg.eu... done.
----

Awesome.  I love making computers spew out pages and pages of output like that
(in fact I find it hard to stop myself from making little 70's computer '<brrp,
brrrp, brrrp>' noises like Mother in Alien).  If we look through it
we can see it is doing our bidding: the `mkdir -p` commands go through
happily, even though the directories already exist.  Next `git pull` pulls down
the couple of commits we just made.  The `sed` and `echo >>` modify our
'settings'py. Then `pip3 install -r requirements.txt`, completes happily,
noting that the existing virtualenv already has all the packages we need.
`collectstatic` also notices that the static files are all already there, and
finally the `syncdb` completes without a hitch.

So, let's try using it for our live site!

[subs="specialcharacters,macros"]
----
$ pass:quotes[*fab deploy:host=harry@superlists.ottg.eu*]

$ fab deploy --host=superlists.ottg.eu
[superlists.ottg.eu] Executing task 'deploy'
[superlists.ottg.eu] run: mkdir -p /home/harry/sites/superlists.ottg.eu
[superlists.ottg.eu] run: mkdir -p /home/harry/sites/superlists.ottg.eu/database
[superlists.ottg.eu] run: mkdir -p /home/harry/sites/superlists.ottg.eu/static
[superlists.ottg.eu] run: mkdir -p /home/harry/sites/superlists.ottg.eu/virtualenv
[superlists.ottg.eu] run: mkdir -p /home/harry/sites/superlists.ottg.eu/source
[superlists.ottg.eu] run: git clone https://github.com/hjwp/book-example.git /home/harry/sites/superlists.ottg.eu/source
[superlists.ottg.eu] out: Cloning into '/home/harry/sites/superlists.ottg.eu/source'...
[superlists.ottg.eu] out: remote: Counting objects: 3128, done.
[superlists.ottg.eu] out: Receiving objects:   0% (1/3128)   
[...]
[superlists.ottg.eu] out: Receiving objects: 100% (3128/3128), 2.60 MiB | 829 KiB/s, done.
[superlists.ottg.eu] out: Resolving deltas: 100% (1545/1545), done.
[superlists.ottg.eu] out: 

[localhost] local: git log -n 1 --format=%H
[superlists.ottg.eu] run: cd /home/harry/sites/superlists.ottg.eu/source && git reset --hard 6c8615b6df4d766cb1f54d17d570e42d2db678f7
[superlists.ottg.eu] out: HEAD is now at 6c8615b use a secret key file
[superlists.ottg.eu] out: 

[superlists.ottg.eu] run: sed -i.bak -r -e 's/DEBUG = True/DEBUG = False/g' "$(echo /home/harry/sites/superlists.ottg.eu/source/superlists/settings.py)"
[superlists.ottg.eu] run: echo 'ALLOWED_HOSTS = ["superlists.ottg.eu"]' >> "$(echo /home/harry/sites/superlists.ottg.eu/source/superlists/settings.py)"
[superlists.ottg.eu] run: echo 'SECRET_KEY = '\\''mqu(ffwid5vleol%ke^jil*x1mkj-44wz(7$f&^q2p15^4a(u!'\\''' >> "$(echo /home/harry/sites/superlists.ottg.eu/source/superlists/secret_key.py)"
[superlists.ottg.eu] run: echo 'from .secret_key import SECRET_KEY' >> "$(echo /home/harry/sites/superlists.ottg.eu/source/superlists/settings.py)"
[superlists.ottg.eu] run: virtualenv --python=python3.3 /home/harry/sites/superlists.ottg.eu/source/../virtualenv
[superlists.ottg.eu] out: Already using interpreter /usr/bin/python3.3
[superlists.ottg.eu] out: Using base prefix '/usr'
[superlists.ottg.eu] out: New python executable in /home/harry/sites/superlists.ottg.eu/source/../virtualenv/bin/python3.3
[superlists.ottg.eu] out: Also creating executable in /home/harry/sites/superlists.ottg.eu/source/../virtualenv/bin/python
[superlists.ottg.eu] out: Installing Setuptools..............................................................................................................................................................................................................................done.
[superlists.ottg.eu] out: Installing Pip.....................................................................................................................................................................................................................................................................................................................................done.
[superlists.ottg.eu] out: 

[superlists.ottg.eu] run: /home/harry/sites/superlists.ottg.eu/source/../virtualenv/bin/pip install -r /home/harry/sites/superlists.ottg.eu/source/requirements.txt
[superlists.ottg.eu] out: Downloading/unpacking Django==1.6 (from -r /home/harry/sites/superlists.ottg.eu/source/requirements.txt (line 1))
[superlists.ottg.eu] out:   Downloading Django-1.6.tar.gz (8.0MB): 
[...]
[superlists.ottg.eu] out:   Downloading Django-1.6.tar.gz (8.0MB): 100%  8.0MB
[superlists.ottg.eu] out:   Running setup.py egg_info for package Django
[superlists.ottg.eu] out:     
[superlists.ottg.eu] out:     warning: no previously-included files matching '__pycache__' found under directory '*'
[superlists.ottg.eu] out:     warning: no previously-included files matching '*.py[co]' found under directory '*'
[superlists.ottg.eu] out: Downloading/unpacking gunicorn==17.5 (from -r /home/harry/sites/superlists.ottg.eu/source/requirements.txt (line 2))
[superlists.ottg.eu] out:   Downloading gunicorn-17.5.tar.gz (367kB): 100%  367kB
[...]
[superlists.ottg.eu] out:   Downloading gunicorn-17.5.tar.gz (367kB): 367kB downloaded
[superlists.ottg.eu] out:   Running setup.py egg_info for package gunicorn
[superlists.ottg.eu] out:     
[superlists.ottg.eu] out: Installing collected packages: Django, gunicorn
[superlists.ottg.eu] out:   Running setup.py install for Django
[superlists.ottg.eu] out:     changing mode of build/scripts-3.3/django-admin.py from 664 to 775
[superlists.ottg.eu] out:     
[superlists.ottg.eu] out:     warning: no previously-included files matching '__pycache__' found under directory '*'
[superlists.ottg.eu] out:     warning: no previously-included files matching '*.py[co]' found under directory '*'
[superlists.ottg.eu] out:     changing mode of /home/harry/sites/superlists.ottg.eu/virtualenv/bin/django-admin.py to 775
[superlists.ottg.eu] out:   Running setup.py install for gunicorn
[superlists.ottg.eu] out:     
[superlists.ottg.eu] out:     Installing gunicorn_paster script to /home/harry/sites/superlists.ottg.eu/virtualenv/bin
[superlists.ottg.eu] out:     Installing gunicorn script to /home/harry/sites/superlists.ottg.eu/virtualenv/bin
[superlists.ottg.eu] out:     Installing gunicorn_django script to /home/harry/sites/superlists.ottg.eu/virtualenv/bin
[superlists.ottg.eu] out: Successfully installed Django gunicorn
[superlists.ottg.eu] out: Cleaning up...
[superlists.ottg.eu] out: 

[superlists.ottg.eu] run: cd /home/harry/sites/superlists.ottg.eu/source && ../virtualenv/bin/python3 manage.py collectstatic --noinput
[superlists.ottg.eu] out: Copying '/home/harry/sites/superlists.ottg.eu/source/lists/static/base.css'
[superlists.ottg.eu] out: Copying '/home/harry/sites/superlists.ottg.eu/source/lists/static/bootstrap/fonts/glyphicons-halflings-regular.ttf'
[...]
[superlists.ottg.eu] out: Copying '/home/harry/sites/superlists.ottg.eu/source/lists/static/bootstrap/css/bootstrap.css'
[superlists.ottg.eu] out: 
[superlists.ottg.eu] out: 11 static files copied.
[superlists.ottg.eu] out: 

[superlists.ottg.eu] run: cd /home/harry/sites/superlists.ottg.eu/source && ../virtualenv/bin/python3 manage.py syncdb --noinput
[superlists.ottg.eu] out: Creating tables ...
[superlists.ottg.eu] out: Creating table auth_permission
[...]
[superlists.ottg.eu] out: Creating table lists_item
[superlists.ottg.eu] out: Installing custom SQL ...
[superlists.ottg.eu] out: Installing indexes ...
[superlists.ottg.eu] out: Installed 0 object(s) from 0 fixture(s)
[superlists.ottg.eu] out: 


Done.
Disconnecting from superlists.ottg.eu... done.

----


'Brrp brrp brpp'. You can see the script follows a slightly different path,
doing a `git clone` to bring down a brand new repo instead of the `git pull`.
It also needs to set up a new virtualenv from scratch, including a fresh
install of pip and Django. The `collectstatic` actually creates new files this
time, and the `syncdb` seems to have worked too.

What else do we need to do to get our live site into production? We refer to
our provisioning notes, which tell us to use the template files to create our
nginx virtual host and the upstart script.  How about a little Unix
command-line magic?

.server command
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sed "s/SITENAME/superlists.ottg.eu/g" deploy_tools/nginx.template.conf | \
    sudo tee /etc/nginx/sites-available/superlists.ottg.eu*
----

`sed` ("stream editor") takes a stream of text and performs edits on it. It's no
accident that the fabric string substitution command has the same name.  In
this case we ask it to substitute the string 'SITENAME' for the address of
our site, with the `s/replaceme/withthis/g` syntax.  We pipe (`|`) the output
of that to a root-user process (sudo) which uses `tee` to write what's piped
to it to a file, in this case the nginx sites-available virtualhost config
file.

We can now activate that file:

.server command
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo ln -s ../sites-available/superlists.ottg.eu \
    /etc/nginx/sites-enabled/superlists.ottg.eu*
----

Now we write the upstart script:

.server command
[subs="specialcharacters,quotes"]
----
elspeth@server: *sed "s/SITENAME/superlists.ottg.eu/g" deploy_tools/gunicorn-upstart.template.conf | \
    sudo tee /etc/init/gunicorn-superlists.ottg.eu.conf*
----

And now we start both services:

.server commands
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo service nginx reload*
elspeth@server:$ *sudo start gunicorn-superlists.ottg.eu*
----

And we take a look at our site.  It works, hooray! 

Let's add the fabfile to our repo:

[subs="specialcharacters,quotes"]
----
$ *git add deploy_tools/fabfile.py*
$ *git commit -m "Add a fabfile for automated deploys"*
----

Git tag the release
~~~~~~~~~~~~~~~~~~~

One final bit of admin.  In order to preserve a historical marker,
we'll use git tags to mark the state of the codebase that reflects
what's currently live on the server:

[subs="specialcharacters,quotes"]
----
$ *git tag LIVE*
$ *export TAG=`date +DEPLOYED-%F/%H%M`*  # this generates a timestamp
$ *echo $TAG*
$ *git tag $TAG*
$ *git push origin LIVE $TAG* # pushes the tags up
----

Now it's easy, at any time, to check what the difference is between
our current codebase and what's live on the servers.  This will come
in useful in a few chapters, when we look at database migrations. Have
a look at the tag in the history:

[subs="specialcharacters,quotes"]
----
$ *git log --graph --oneline --decorate*
----


Anyway, you now have a live website!  Tell all your friends!  Tell your mum, if
no-one else is interested! And, in the next chapter, it's back to coding
again...

Recap:
~~~~~

Lots of this, particularly on the provisioning side, was very specific to the
setup I happened to use.  When you deploy sites, you might use Apache instead
of nginx, uWSGI instead of Gunicorn, Supervisor instead of Upstart, and so on.
If you use a PaaS, some of these problems will be solved for you, others won't.
But I really wanted to take you through a practical example, so we could see
some of the concerns involved in deployment.

There are some elements that will be common to almost all situations though:

* You need to choose a place for your static files
* You'll need specific config for your database
* You need to run some kind of webserver, set it to listen on some port

On the deployment side, you should find that much of what we've done is
transferable to any situation:

* During a deploy, you need a way to 'update your source code'.  We're using
`git pull`.
* You need a way to update your 'static files' (`collectstatic`)
* You need to update your 'database' (`syncdb` for now, we'll look at 
South and schema migrations later)
* You need to manage your dependencies, and make sure any packages you need
are available on the server. We use a 'virtualenv' to isolate our various
sites from each other.
* You'll probably need to tweak some items in 'settings.py' when switching
to production.
* You'll want to 'test' that these things work, by doing your deployment to a
staging site first
* You should be able to run your functional test suite against the 'staging site'.
* You'll want to 'automate' all of the steps involved in a deploy, to give
yourself confidence that when you deploy to live, things will go just as
smoothly as when you deployed to staging.


Further reading:
~~~~~~~~~~~~~~~~

I'm no grizzled expert on deployment.  I've tried to set you off on a
reasonably sane path, but there's lots of things you could do differently,
and lots, lots more to learn besides.  Here are some articles I used for
inspiration:

* <<python-deployments,Solid Python Deployments for Everybody, by Hynek Schlawack>>
* <<gitric,Git-based fabric deployments are awesome, by Dan Bravender>>

For some ideas on how you might go about automating the provisioning step,
and an alternative to Fabric, go check out <<appendix2,Appendix III>>.


Todos
~~~~~~

There's no such thing as the One True Way in deployment, and as I say I'm no 
kind of expert.  I hope that this chapter will change and improve over the
coming months, especially thanks to the feedback of beloved readers!

Here's a few things I'm thinking of changing or adding.  Let me know what you
think, and what else should be on the list! obeythetestinggoat@gmail.com

Chapter Objectives:

- As simple as possible
- But no simpler
- Illustrate some (the main?) challenges of deployment
- Show where TDD fits in
- Try and make it reminiscent of the environment you'd get in a PaaS

Possible changes:

- setup logging... but how best?  and where to put log files?
- setuid in upstart script
- using /home/username to make it "like shared hosting" -- is that totally
  outdated?  Should I just put everything in /var/www?

//TODO: recap on what local state and server state should be.

