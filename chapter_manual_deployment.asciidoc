[[chapter_manual_deployment]]
Testing Deployment Using a Staging Site
---------------------------------------

[%autowidth,float="right",caption=,cols="2"]
|=======
2+|Chapter info
|shortname:|chapter_manual_deployment
|=======

WARNING: Major update released for Selenium 3.
    If you started this book on or before Jan 30th 2017,
    be aware: chapters have been renumbered,
    so check this is the one you think it is,
    and have a look at the new <<chapter_explicit_waits_1>>
    for an indication of the changes you'll need in your FTs.
    You should do a `pip install --upgrade selenium` too.




[quote, 'https://twitter.com/DEVOPS_BORAT/status/192271992253190144[Devops Borat]']
______________________________________________________________
Is all fun and game until you are need of put it in production.
______________________________________________________________


((("deployment testing", id="ix_deptest", range="startofrange")))
It's time to deploy the first version of our site and make it public.  They say
that if you wait until you feel ready to ship, then you've waited too long.

Is our site usable?  Is it better than nothing? Can we make lists on it? Yes,
yes, yes.

No, you can't log in yet.  No, you can't mark tasks as completed.  But do we
really need any of that stuff? Not really--and you can never be sure what
your users are 'actually' going to do with your site once they get their 
hands on it. We think our users want to use the site for to-do lists, but maybe
they actually want to use it to make "top 10 best fly-fishing spots" lists, for
which you don't need any kind of ``mark completed'' function. We won't know
until we put it out there.

In this chapter we're going to go through and actually deploy our site to a
real, live web server.  

You might be tempted to skip this chapter--there's lots of daunting stuff
in it, and maybe you think this isn't what you signed up for. But I 'strongly' 
urge you to give it a go.  This is one of the chapters I'm most pleased with,
and it's one that people often write to me saying they were really glad they
stuck through it. 

If you've never done a server deployment before, it will demystify a whole
world for you, and there's nothing like the feeling of seeing your site live on
the actual Internet. Give it a buzzword name like "DevOps" if that's what it
takes to convince you it's worth it.

NOTE: Why not ping me a note once your site is live on the web, and send me
    the URL? It always gives me a warm and fuzzy feeling...
    obeythetestinggoat@gmail.com.


TDD and the Danger Areas of Deployment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Deploying a site to a live web server can be a tricky topic.  Oft-heard is the
forlorn cry&mdash;"'but it works on my machine!'".

((("deployment", "danger areas")))
Some of the danger areas of deployment include:

Static files (CSS, JavaScript, images, etc.)::
    Web servers usually need special configuration for serving these.
    ((("static files")))

The database:: 
    There can be permissions and path issues, and we need to be careful about
    preserving data between deploys.
    ((("database deployment issues")))

Dependencies:: 
    We need to make sure that the packages our software relies on are installed
    on the server, and have the correct versions.
    ((("dependencies", "and deployment")))
    ((("deployment", "dependencies and")))

But there are solutions to all of these.  In order:

*   Using a 'staging site', on the same infrastructure as the production site,
    can help us test out our deployments and get things right before we go to
    the "real" site.
    ((("staging sites")))

*   We can also 'run our functional tests against the staging site'. That will
    reassure us that we have the right code and packages on the server, and
    since we now have a "smoke test" for our site layout, we'll know that the
    CSS is loaded correctly.
    ((("functional tests/testing (FT)", "for staging sites", sortas="stagingsites")))

*   Just like on our own PC, a 'Virtualenv' is useful on the server for
    managing packages and dependencies when you might be running more than one
    Python application.
    ((("virtualenvs")))

*   And finally, 'automation, automation, automation'.  By using an automated
    script to deploy new versions, and by using the same script to deploy to
    staging and production, we can reassure ourselves that staging is as much
    like live as
    possible.footnote:[What I'm calling a "staging" server, some people would
    call a "development" server, and some others would also like to distinguish
    "preproduction" servers.  Whatever we call it, the point is to have
    somewhere we can try our code out in an environment that's as similar as
    possible to the real production server.] 
    ((("automation, in deployment")))
    ((("scripts, automated"))) 

Over the next few pages I'm going to go through 'a' deployment procedure.  It 
isn't meant to be the 'perfect' deployment procedure, so please don't take
it as being best practice, or a recommendation--it's meant to be an
illustration, to show the kinds of issues involved in deployment and where
testing fits in.

.Chapter Overview
*******************************************************************************

((("deployment testing", "overview")))
There's lots of stuff in this chapter, so here's an overview to help you keep
your bearings:

. Adapt our FTs so they can run against a staging server.

. Spin up a server, install all the required software on it, and point our
  staging and live domains at it.

. Upload our code to the server using Git.

. Try and get a quick & dirty version of our site running on the staging domain
  using the Django dev server.

. Manually set up a virtualenv on the server (without virtualenvwrapper).

. As we go, we'll keep running our FT, to tell us what's working and what's
  not.

. Move from our quick & dirty version to a production-ready configuration,
  using Gunicorn, Systemd, and domain sockets.

. Once we have a working config, we'll write a script to automate the process
  we've just been through manually, so that we can deploy our site
  automatically in future.

. Finally we'll use this script to deploy the production version of our site
  on its real domain.

*******************************************************************************



As Always, Start with a Test
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

((("staging sites")))
((("functional tests/testing (FT)", "for staging sites", sortas="stagingsites")))
Let's adapt our functional tests slightly so that it can be run against
a staging site. We'll do it by slightly hacking an argument that is normally
used to change the address which the test's temporary server gets run on:


[role="sourcecode"]
.functional_tests/tests.py (ch08l001)
[source,python]
----
import sys
[...]

class NewVisitorTest(StaticLiveServerTestCase):

    def setUp(self):
        self.browser = webdriver.Firefox()
        staging_server = os.environ.get('STAGING_SERVER')  #<1>
        if staging_server:
            setattr(self, 'live_server_url', 'http://' + staging_server)  #<2>
----


Do you remember I said that `LiveServerTestCase` had certain limitations?
Well, one is that it always assumes you want to use its own test server, which
it makes available at `self.live_server_url`.  I still want to be able to do
that sometimes, but I also want to be able to selectively tell it not to
bother, and to use a real server instead.

<1> The way I decided to do it is using an environment variable called
    `STAGING_SERVER`

<2> We can't just assign to `self.live_server_url` because it's a special
    property on this class, but we can get around that by using `setattr`.
    I did promise you a 
    hackfootnote:[At this point, you can google "setattr" and
    "Python properties" if your curiosity is piqued.]!

We test that said hack hasn't broken anything by running the functional
tests "normally":

[subs="specialcharacters,macros"]
----
$ pass:quotes[*python manage.py test functional_tests*] 
[...]
Ran 3 tests in 8.544s

OK
----

And now we can try them against our staging server URL.  I'm hosting my staging
server at 'superlists-staging.ottg.eu':


//would need to reset DNS each time for this test to work

[role="skipme"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*STAGING_SERVER=superlists-staging.ottg.eu python manage.py test functional_tests*]

======================================================================
FAIL: test_can_start_a_list_for_one_user
(functional_tests.tests.NewVisitorTest)
 ---------------------------------------------------------------------
Traceback (most recent call last):
  File "/.../superlists/functional_tests/tests.py", line 49, in
test_can_start_a_list_and_retrieve_it_later
    self.assertIn('To-Do', self.browser.title)
AssertionError: 'To-Do' not found in 'Domain name registration | Domain names
| Web Hosting | 123-reg'
[...]


======================================================================
FAIL: test_multiple_users_can_start_lists_at_different_urls
(functional_tests.tests.NewVisitorTest)
 ---------------------------------------------------------------------
Traceback (most recent call last):
  File
"/.../superlists/functional_tests/tests.py", line 86, in
test_layout_and_styling
    inputbox = self.browser.find_element_by_id('id_new_item')
[...]
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate
element: {"method":"id","selector":"id_new_item"}
[...]


======================================================================
FAIL: test_layout_and_styling (functional_tests.tests.NewVisitorTest)
 ---------------------------------------------------------------------
Traceback (most recent call last):
  File
[...]
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate
element: {"method":"id","selector":"id_new_item"}
[...]

Ran 3 tests in 19.480s:

FAILED (failures=3)
----

You can see that both tests are failing, as expected, since I haven't
actually set up my staging site yet. In fact, you can see from the
first traceback that the test is actually ending up on the home page of
my domain registrar.

The FT seems to be testing the right things though, so let's commit:

[subs="specialcharacters,quotes"]
----
$ *git diff* # should show changes to functional_tests.py
$ *git commit -am "Hack FT runner to be able to test staging"*
----


Getting a Domain Name
~~~~~~~~~~~~~~~~~~~~~

((("deployment testing", "domain name for")))
((("staging sites")))
((("domain names")))
We're going to need a couple of domain names at this point in the book--they
can both be subdomains of a single domain.  I'm going to use
'superlists.ottg.eu' and 'superlists-staging.ottg.eu'.
If you don't already own a domain, this is the time to register one! Again,
this is something I really want you to 'actually' do.  If you've never
registered a domain before, just pick any old registrar and buy a cheap one--it
should only cost you $5 or so, and you can even find free ones.
I promise seeing your site on a "real" web site will be a thrill.


Manually Provisioning a Server to Host Our Site
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

((("deployment testing", "manual provisioning for hosting", id="ix_deptestprov", range="startofrange")))
((("hosting, manual provisioning", id="ix_hostingmp", range="startofrange")))
((("servers", id="ix_servermp", range="startofrange", seealso="staging server")))
((("provisioning", id="ix_provisioning", range="startofrange")))
We can separate out "deployment" into two tasks:

- 'Provisioning' a new server to be able to host the code
- 'Deploying' a new version of the code to an existing server

Some people like to use a brand new server for every deployment--it's what we
do at PythonAnywhere.  That's only necessary for larger, more complex sites
though, or major changes to an existing site. For a simple site like ours, it
makes sense to separate the two tasks.  And, although we eventually want both
to be completely automated, we can probably live with a manual provisioning
system for now.

As you go through this chapter, you should be aware that provisioning is
something that varies a lot, and that as a result there are few universal
best practices for deployment.  So, rather than trying to remember the 
specifics of what I'm doing here, you should be trying to understand the
rationale, so that you can apply the same kind of thinking in the
specific future circumstances you encounter.


Choosing Where to Host Our Site
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("hosting options")))
There are loads of different solutions out there these days, but they broadly
fall into two camps:

- Running your own (possibly virtual) server
- Using a Platform-As-A-Service (PaaS) offering like Heroku, DotCloud,
  OpenShift, or PythonAnywhere

((("Platform-as-a-Service (PaaS)")))
((("PaaS (Platform-as-a-Service)")))
((("PythonAnywhere")))
Particularly for small sites, a PaaS offers a lot of advantages, and I would
definitely recommend looking into them.  We're not going to use a PaaS in this
book however, for several reasons.  Firstly, I have a conflict of interest, in
that I think PythonAnywhere is the best, but then again I would say that
because I work there.  Secondly, all the PaaS offerings are quite different,
and the procedures to deploy to each vary a lot--learning about one doesn't
necessarily tell you about the others. Any one of them might change their
process radically, or simply go out of business by the time you get to read
this book.

Instead, we'll learn just a tiny bit of good old-fashioned server admin,
including SSH and web server config.  They're unlikely to ever go away, and
knowing a bit about them will get you some respect from all the grizzled
dinosaurs out there.

What I have done is to try and set up a server in such a way that it's a lot
like the environment you get from a PaaS, so you should be able to apply the
lessons we learn in the deployment section, no matter what provisioning
solution you choose.


Spinning Up a Server
^^^^^^^^^^^^^^^^^^^^

((("server options")))
((("Ubuntu")))
I'm not going to dictate how you do this--whether you choose Amazon AWS,
Rackspace, Digital Ocean, your own server in your own data centre or a
Raspberry Pi in a cupboard behind the stairs, any solution should be fine, as
long as:

* Your server is running Ubuntu 16.04 (aka "Xenial/LTS")

* You have root access to it.

* It's on the public Internet.

* You can SSH into it.

I'm recommending Ubuntu as a distro because it has Python 3.6 and it has some
specific ways of configuring Nginx, which I'm going to make use of next.  If
you know what you're doing, you can probably get away with using something
else, but you're on your own.


NOTE: Some people get to this chapter, and are tempted to skip the domain bit,
and the "getting a real server" bit, and just use a VM on their own PC.  Don't
do this. It's 'not' the same, and you'll have more difficulty following the
instructions, which are complicated enough as it is.  If you're worried about
cost, dig around and you'll find free options for both. Email me if you need
further pointers, I'm always happy to help.


User Accounts, SSH, and Privileges
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("nonroot user creation")))
In these instructions, I'm assuming that you have a nonroot user account set
up that has "sudo" privileges, so whenever we need to do something that
requires root access, we use sudo, and I'm explicit about that in the various
instructions below. If you need to create a nonroot user, here's how:

[role="skipme"]
[subs="specialcharacters,quotes"]
----
# these commands must be run as root
root@server:$ *useradd -m -s /bin/bash elspeth* # add user named elspeth 
# -m creates a home folder, -s sets elspeth to use bash by default
root@server:$ *usermod -a -G sudo elspeth* # add elspeth to the sudoers group
root@server:$ *passwd elspeth* # set password for elspeth
root@server:$ *su - elspeth* # switch-user to being elspeth!
elspeth@server:$ 
----

((("private key authentication")))
Name your own user whatever you like! I also recommend learning up how to use
private key authentication rather than passwords for SSH.  It's a matter of
taking the public key from your own PC, and appending it to
'~/.ssh/authorized_keys' in the user account on the server. You probably went
through a similar procedure if you signed up for Bitbucket or Github.

There are some good instructions
https://library.linode.com/security/ssh-keys[here] (note that `ssh-keygen` 'is'
available as part of Git-Bash on Windows).

TIP: Look out for that `elspeth@server` in the command-line listings in this
    chapter. It indicates commands that must be run on the server, as opposed
    to commands you run on your own PC.


Installing Nginx 
^^^^^^^^^^^^^^^^

((("Nginx")))
We'll need a web server, and all the cool kids are using Nginx these days,
so we will too.  Having fought with Apache for many years, I can tell
you it's a blessed relief in terms of the readability of its config files,
if nothing else!

Installing Nginx on my server was a matter of doing an `apt-get`, and I could
then see the default Nginx "Hello World" screen:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo apt-get install nginx*
elspeth@server:$ *sudo systemctl start nginx*
----

(You may need to do an `apt-get update` and/or an `apt-get upgrade` first.)



You should be able to go to the IP address of your server, and see the
"Welcome to nginx" page at this point, as in <<nginx-it-works>>.

If you don't see it, it may be because your firewall does not open port 80 to
the world. On AWS for example, you may need to configure the "security group"
for your server to open port 80.

[[nginx-it-works]]
.Nginx--it works!
image::images/twdp_0801.png["The default 'Welcome to nginx!' page"]


Installing Python 3.6
^^^^^^^^^^^^^^^^^^^^^

Python 3.6 wasn't available in the standard repositories on Ubuntu at the
time of writing, but the user-contributed
https://launchpad.net/~fkrull/+archive/ubuntu/deadsnakes["Deadsnakes PPA"]
has it.  Here's how we install it:


While we've got root access, let's make sure the server has the key
pieces of software we need at the system level: Python, Git, pip, and virtualenv.

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo add-apt-repository ppa:fkrull/deadsnakes*
elspeth@server:$ *sudo apt-get update*
elspeth@server:$ *sudo apt-get install python3.6 python3.6-venv*
----

And while we're at it, we'll just make sure git is installed too.

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo apt-get install git*
----


Configuring Domains for Staging and Live
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We don't want to be messing about with IP addresses all the time, so we should
point our staging and live domains to the server. At my registrar, the control
screens looked a bit like <<registrar-control-screens>>.

[[registrar-control-screens]]
.Domain setup
image::images/twdp_0802.png["Registrar control screens for two domains"]

//TODO: adjust illustration to show "superlists" not "book-example"

In the DNS system, pointing a domain at a specific IP address is called an
"A-Record".  All registrars are slightly different, but a bit of clicking
around should get you to the right screen in yours.



Using the FT to Confirm the Domain Works and Nginx Is Running
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("functional tests/testing (FT)", "in provisioning", sortas="provisioning")))
((("provisioning", "functional tests (FT) in")))
To confirm  this works, we can rerun our functional tests and see that their
failure messages have changed slightly--one of them in particular should
now mention Nginx:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*STAGING_SERVER=superlists-staging.ottg.eu python manage.py test functional_tests*]
[...]
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate
element: {"method":"id","selector":"id_new_item"}
[...]
AssertionError: 'To-Do' not found in 'Welcome to nginx!'
----

Progress!
(((range="endofrange", startref="ix_deptestprov")))
(((range="endofrange", startref="ix_hostingmp")))
(((range="endofrange", startref="ix_servermp")))
(((range="endofrange", startref="ix_provisioning")))


Deploying Our Code Manually
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The next step is to get a copy of the staging site up and running, just to
check whether we can get Nginx and Django to talk to each other.  As we do so,
we're starting to move into doing "deployment" rather than provisioning, so we
should be thinking about how we can automate the process, as we go.

NOTE: One rule of thumb for distinguishing provisioning from deployment is
that you tend to need root permissions for the former, but we don't for the
latter.
((("provisioning", "vs. deployment")))
((("deployment", "vs. provisioning", sortas="provisioning")))

We need a directory for the source to live in.  Let's assume we have a home
folder for a nonroot user; in my case it would be at '/home/elspeth' (this is
likely to be the setup on any shared hosting system, but you should always run
your web apps as a nonroot user, in any case). I'm going to set up my
sites like this:

[role="skipme"]
----
/home/elspeth
├── sites
│   ├── www.live.my-website.com
│   │    ├── database
│   │    │     └── db.sqlite3
│   │    ├── source
│   │    │    ├── manage.py
│   │    │    ├── superlists
│   │    │    ├── etc...
│   │    │
│   │    ├── static
│   │    │    ├── base.css
│   │    │    ├── etc...
│   │    │
│   │    └── virtualenv
│   │         ├── lib
│   │         ├── etc...
│   │
│   ├── www.staging.my-website.com
│   │    ├── database
│   │    ├── etc...
----

Each site (staging, live, or any other website) has its own folder. Within that
we have a separate folder for the source code, the database, and the static
files.  The logic is that, while the source code might change from one version
of the site to the next, the database will stay the same.  The static folder
is in the same relative location, '../static', that we set up at the end of
the last chapter. Finally, the virtualenv gets its own subfolder too (on the
server, there's no need to use virtualenvwrapper, we'll create a virtualenv
manually).


Adjusting the Database Location
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("deployment", "adjusting database location")))
((("database location")))
First let's change the location of our database in 'settings.py', and make sure
we can get that working on our local PC:

[role="sourcecode"]
.superlists/settings.py (ch08l003)
[source,python]
----
# Build paths inside the project like this: os.path.join(BASE_DIR, ...)
import os
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
[...]

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': os.path.join(BASE_DIR, '../database/db.sqlite3'),
    }
}
----

TIP: Check out the way `BASE_DIR` is defined, further up in 'settings.py'.
Notice the `abspath` gets done first (i.e., innermost).  Always follow this
pattern when path-wrangling, otherwise you can see strange things happening
depending on how the file is imported.  Thanks to
https://github.com/CleanCut/green[Green Nathan] for that tip!


Now let's try it locally:

[subs="specialcharacters,quotes"]
----
$ *mkdir ../database*
$ *python manage.py migrate --noinput*
Creating tables ...
[...]
$ *ls ../database/*
db.sqlite3
----

That seems to work.  Let's commit it:

[subs="specialcharacters,quotes"]
----
$ *git diff* # should show changes in settings.py
$ *git commit -am "move sqlite database outside of main source tree"*
----

To get our code onto the server, we'll use Git and go via one of the code
sharing sites.  If you haven't already, push your code up to GitHub, BitBucket,
or similar.  They all have excellent instructions for beginners on how to
do that.

((("Bash")))
Here's some bash commands that will set this all up. If you're not familiar
with it, note the `export` command which lets me set up a "local variable"
in bash:

[role="server-commands"]
[subs=""]
----
elspeth@server:$ <strong>export SITENAME=superlists-staging.ottg.eu</strong>
elspeth@server:$ <strong>mkdir -p ~/sites/$SITENAME/database</strong>
elspeth@server:$ <strong>mkdir -p ~/sites/$SITENAME/static</strong>
elspeth@server:$ <strong>mkdir -p ~/sites/$SITENAME/virtualenv</strong>
# you should replace the URL in the next line with the URL for your own repo
elspeth@server:$ <strong>git clone https://github.com/hjwp/book-example.git \
~/sites/$SITENAME/source</strong>
Resolving deltas: 100% [...]
----

NOTE: A bash variable defined using `export` only lasts as long as that console
session. If you log out of the server and log back in again, you'll need to
redefine it. It's devious because Bash won't error, it will just substitute
the empty string for the variable, which will lead to weird results...if in
doubt, do a quick *`echo $SITENAME`*.

Now we've got the site installed, let's just try running the dev server--this
is a smoke test, to see if all the moving parts are connected:

[role="skipme"]
[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ $ *cd ~/sites/$SITENAME/source*
$ *python manage.py runserver*
Traceback (most recent call last):
  File "manage.py", line 8, in <module>
    from django.core.management import execute_from_command_line
ImportError: No module named django.core.management
----
//cant test this because we hack runservers using dtach

Ah. Django isn't installed on the server.


Creating a Virtualenv manually, and using requirements.txt
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("deployment", "virtualenvs", id="ix_deployvirtenvs", range="startofrange")))
To "save" the list of packages we need in our virtualenv, and be able to
re-create it on the server, we create a 'requirements.txt' file:

[subs="specialcharacters,quotes"]
----
$ *echo "Django==1.11.5" > requirements.txt*
$ *git add requirements.txt*
$ *git commit -m "Add requirements.txt for virtualenv"*
----

NOTE: You may be wondering why we didn't add our other dependency,
    selenium, to our requirements.  The reason is that selenium is
    only a dependency for the tests, not the application code.  Some
    people like to also create a file called 'test-requirements.txt'.

Now we do a `git push` to send our updates up to our code-sharing site:

[role="skipme"]
[subs="specialcharacters,quotes"]
----
$ *git push*
----

And we can pull those changes down to the server: 

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *git pull*  # may ask you to do some git config first
----


Creating a virtualenv "manually" (ie, without virtualenvwraper) involves
using the standard library "venv" module, and specifying the path you
want the virtualenv to go in:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *pwd*
/home/espeth/sites/staging.superlists.com/source
elspeth@server:$ *python3.6 -m venv ../virtualenv*
elspeth@server:$ *ls ../virtualenv/bin*
activate      activate.fish  easy_install-3.6  pip3    python
activate.csh  easy_install   pip               pip3.6  python3
----

If we wanted to activate the virtualenv, we could do so with
`source ../virtualenv/bin/activate`, but we don't need to do
that.  We can actually do everything we want to by calling the versions
of Python, pip, and the other executables in the virtualenv's 'bin'
directory, as we'll see.

To install our requirements into the virtualenv, we use the virtualenv
pip:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *../virtualenv/bin/pip install -r requirements.txt*
Downloading/unpacking Django==1.11.5 (from -r requirements.txt (line 1))
[...]
Successfully installed Django
----


And to run Python in the virtualenv, we use the virtualenv `python`
binary:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *../virtualenv/bin/python manage.py runserver*
Validating models...
0 errors found
[...]
----

That looks like it's running happily.  We can Ctrl-C it for now.
(((range="endofrange", startref="ix_deployvirtenvs")))


Simple Nginx Configuration
^^^^^^^^^^^^^^^^^^^^^^^^^^

((("Nginx", id="ix_Nginx", range="startofrange")))
((("deployment", "Nginx", id="ix_deploynginx", range="startofrange")))
Next we create an Nginx config file to tell it to send requests for our staging
site along to Django. A minimal config looks like this:

[role="sourcecode"]
.server: /etc/nginx/sites-available/superlists-staging.ottg.eu
[source,nginx]
----
server {
    listen 80;
    server_name superlists-staging.ottg.eu;

    location / {
        proxy_pass http://localhost:8000;
    }
}
----

This config says it will only work for our staging domain, and will "proxy"
all requests to the local port 8000 where it expects to find Django
waiting to respond to requests.



I saved this to a file called 'superlists-staging.ottg.eu'
inside the '/etc/nginx/sites-available' folder

NOTE: Not sure how to edit a file on the server?  There's always vi, which I'll
    keep encouraging you to learn a bit of. Alternatively, try the relatively
    beginner-friendly 
    http://www.howtogeek.com/howto/42980/the-beginners-guide-to-nano-the-linux-command-line-text-editor/[`nano`].
    Note you'll also need to use `sudo` because the file is in a system folder.

We then add it to the enabled sites for the server by creating a symlink to it:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *echo $SITENAME* # check this still has our site in
superlists-staging.ottg.eu
elspeth@server:$ *sudo ln -s ../sites-available/$SITENAME \
/etc/nginx/sites-enabled/$SITENAME*
elspeth@server:$ *ls -l /etc/nginx/sites-enabled* # check our symlink is there
----

That's the Debian/Ubuntu preferred way of saving Nginx configurations--the real
config file in 'sites-available', and a symlink in 'sites-enabled'; the idea is
that it makes it easier to switch sites on or off.

We also may as well remove the default "Welcome to nginx" config, to avoid any
confusion:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo rm /etc/nginx/sites-enabled/default*
----

And now to test it:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo systemctl reload nginx*
elspeth@server:$ *../virtualenv/bin/python manage.py runserver*
----

NOTE: I also had to edit '/etc/nginx/nginx.conf' and uncomment a line saying
`server_names_hash_bucket_size 64;` to get my long domain name to work.  You 
may not have this problem; Nginx will warn you when you do a `reload` if it has
any trouble with its config files.

A quick visual inspection confirms--the site is up (<<staging-is-up>>)!

[[staging-is-up]]
.The staging site is up!
image::images/twdp_0803.png["The front page of the site, at least, is up"]

TIP: If you ever find Nginx isn't behaving as expected, try the command
`sudo nginx -t`, which does a config test, and will warn you of any 
problems in your configuration files.

Let's see what our functional tests say:
// don't have selenium installed in there...

[subs="specialcharacters,macros"]
----
$ pass:quotes[*STAGING_SERVER=superlists-staging.ottg.eu python manage.py test functional_tests*]
[...]
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate
[...]
AssertionError: 0.0 != 512 within 3 delta
----

((("Django", "debugging screen")))
((("debugging", "Django debug screen")))
The tests are failing as soon as they try and submit a new item, because we
haven't set up the database. You'll probably have spotted the yellow Django
debug page (<<django-debug-screen>>) telling us as much as the tests went
through, or if you tried it manually.



NOTE: The tests saved us from potential embarrassment there.  The site 'looked'
fine when we loaded its front page.  If we'd been a little hasty, we might have
thought we were done, and it would have been the first users that discovered
that nasty Django DEBUG page.  Okay, slight exaggeration for effect, maybe we
'would' have checked, but what happens as the site gets bigger and more
complex? You can't check everything. The tests can.
(((range="endofrange", startref="ix_Nginx")))
(((range="endofrange", startref="ix_deploynginx")))



[[django-debug-screen]]
.But the database isn't
image::images/twdp_0804.png["Django DEBUG page showing database error"]

Creating the Database with migrate
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("migrate")))
((("deployment", "migrate")))
We run `migrate` using the `--noinput` argument to suppress the two little "are
you sure" prompts:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *../virtualenv/bin/python manage.py migrate --noinput*
Creating tables ...
[...]
elspeth@server:$ *ls ../database/*
db.sqlite3
elspeth@server:$ *../virtualenv/bin/python manage.py runserver*
----

Let's try the FTs again:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*STAGING_SERVER=superlists-staging.ottg.eu python manage.py test functional_tests*]
[...]

...
 ---------------------------------------------------------------------
Ran 3 tests in 10.718s

OK
----

It's great to see the site up and running!  We might reward ourselves with a
well-earned tea break at this point, before moving on to the next section...

TIP: If you see a "502 - Bad Gateway", it's probably because you forgot to
restart the dev server with `manage.py runserver` after the `migrate`.

//IDEA: this could be a good place to pause and make a new chapter.


Getting to a Production-Ready Deployment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

((("deployment", "production-ready", id="ix_deploymentprodready", range="startofrange")))
We're at least reassured that the basic piping works, but we really can't be
using the Django dev server in production.  We also can't be relying on
manually starting it up with `runserver`.


Switching to Gunicorn
^^^^^^^^^^^^^^^^^^^^^

((("Gunicorn", id="ix_gunicorn", range="startofrange")))
((("Django", "and Gunicorn", sortas="gunicorn")))
Do you know why the Django mascot is a pony?  The story is that Django
comes with so many things you want: an ORM, all sorts of middleware,
the admin site... "What else do you want, a pony?" Well, Gunicorn stands
for "Green Unicorn", which I guess is what you'd want next if you already
had a pony...

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *../virtualenv/bin/pip install gunicorn*
----

Gunicorn will need to know a path to a WSGI server, which is usually
a function called `application`.  Django provides one in 'superlists/wsgi.py':


[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *../virtualenv/bin/gunicorn superlists.wsgi:application*
2013-05-27 16:22:01 [10592] [INFO] Starting gunicorn 0.19.6
2013-05-27 16:22:01 [10592] [INFO] Listening at: http://127.0.0.1:8000 (10592)
[...]
----

If you now take a look at the site, you'll find the CSS is all broken, as in
<<site-with-broken-css>>.


((("functional tests/testing (FT)", "for layout and style", sortas="layoutandstyle")))
And if we run the functional tests, you'll see they confirm that something
is wrong. The test for adding list items passes happily, but the test for 
layout + styling fails.  Good job tests!

[subs="specialcharacters,macros"]
----
$ pass:quotes[*STAGING_SERVER=superlists-staging.ottg.eu python manage.py test functional_tests*]
[...]
AssertionError: 125.0 != 512 within 3 delta
FAILED (failures=1)
----

The reason that the CSS is broken is that although the Django dev server will
serve static files magically for you, Gunicorn doesn't.  Now is the time to
tell Nginx to do it instead.


[[site-with-broken-css]]
.Broken CSS
image::images/twdp_0805.png["The site is up, but CSS is broken"]


Getting Nginx to Serve Static Files
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("Nginx")))
((("static files")))
First we run `collectstatic` to copy all the static files to a folder where 
Nginx can find them:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *../virtualenv/bin/python manage.py collectstatic --noinput*
elspeth@server:$ *ls ../static/*
base.css  bootstrap
----

Now we tell Nginx to start serving those static files for us:

[role="sourcecode"]
.server: /etc/nginx/sites-available/superlists-staging.ottg.eu
[source,nginx]
----
server {
    listen 80;
    server_name superlists-staging.ottg.eu;

    location /static {
        alias /home/elspeth/sites/superlists-staging.ottg.eu/static;
    }

    location / {
        proxy_pass http://localhost:8000;
    }
}
----

Reload Nginx and restart Gunicorn...

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo systemctl reload nginx*
elspeth@server:$ *../virtualenv/bin/gunicorn superlists.wsgi:application*
----

And if we take another look at the site, things are looking much healthier. We
can rerun our FTs:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*STAGING_SERVER=superlists-staging.ottg.eu python manage.py test functional_tests*]
[...]

...
 ---------------------------------------------------------------------
Ran 3 tests in 10.718s

OK
----


Switching to Using Unix Sockets
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("Unix sockets")))
When we want to serve both staging and live, we can't have both servers trying
to use port 8000.  We could decide to allocate different ports, but that's a
bit arbitrary, and it would be dangerously easy to get it wrong and start
the staging server on the live port, or vice versa.

A better solution is to use Unix domain sockets--they're like files on disk,
but can be used by Nginx and Gunicorn to talk to each other.  We'll put our
sockets in '/tmp'.  Let's change the proxy settings in Nginx:

[role="sourcecode"]
.server: /etc/nginx/sites-available/superlists-staging.ottg.eu
[source,nginx]
----
[...]
    location / {
        proxy_set_header Host $host;
        proxy_pass http://unix:/tmp/superlists-staging.ottg.eu.socket;
    }
}
----

`proxy_set_header` is used to make sure Gunicorn and Django know what domain
it's running on.  We need that for the `ALLOWED_HOSTS` security feature, which 
we're about to switch on.

Now we restart Gunicorn, but this time telling it to listen on a socket instead
of on the default port:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
elspeth@server:$ *sudo systemctl reload nginx*
elspeth@server:$ *../virtualenv/bin/gunicorn --bind \
    unix:/tmp/superlists-staging.ottg.eu.socket superlists.wsgi:application*
----


And again, we rerun the functional test again, to make sure things still pass:

[subs="specialcharacters,macros"]
----
$ pass:quotes[*STAGING_SERVER=superlists-staging.ottg.eu python manage.py test functional_tests*]
OK
----

A couple more steps!


Switching DEBUG to False and Setting ALLOWED_HOSTS
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("Django", "debugging screen")))
((("debugging", "switching DEBUG to false")))
((("ALLOWED_HOSTS")))
Django's DEBUG mode is all very well for hacking about on your own server, but
leaving those pages full of tracebacks available
http://bit.ly/SuvluV[isn't secure].

You'll find the `DEBUG` setting at the top of 'settings.py'. When we set this
to `False`, we also need to set another setting called `ALLOWED_HOSTS`. This
was
https://docs.djangoproject.com/en/1.11/ref/settings/#std:setting-ALLOWED_HOSTS[added
as a security feature] in Django 1.5.  Unfortunately it doesn't have a helpful
comment in the default 'settings.py', but we can add one ourselves.  Do this on
the server:

[role="sourcecode"]
.server: superlists/settings.py
[source,python]
----
# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = False

TEMPLATE_DEBUG = DEBUG

# Needed when DEBUG=False
ALLOWED_HOSTS = ['superlists-staging.ottg.eu']
[...]
----

And, once again, we restart Gunicorn and run the FT to check things still work.

NOTE: Don't commit these changes on the server. At the moment this is just a 
hack to get things working, not a change we want to keep in our repo. In
general, to keep things simple, I'm only going to do Git commits from the local
PC, using `git push` and `git pull` when I need to sync them up to the server.



Using Systemd to Make Sure Gunicorn Starts on Boot
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

((("Systemd")))
Our final step is to make sure that the server starts up Gunicorn automatically
on boot, and reloads it automatically if it crashes.  On Ubuntu, the way to do
this is using Systemd:

[role="sourcecode"]
.server: /etc/systemd/system/gunicorn-superlists-staging.ottg.eu.service
[source,bash]
----
[Unit]
Description=Gunicorn server for superlists-staging.ottg.eu

[Service]
Restart=on-failure  <1>
User=elspeth  <2>
WorkingDirectory=/home/elspeth/sites/superlists-staging.ottg.eu/source  <3>
ExecStart=/home/elspeth/sites/superlists-staging.ottg.eu/virtualenv/bin/gunicorn \
    --bind unix:/tmp/superlists-staging.ottg.eu.socket \
    superlists.wsgi:application  <4>

[Install]
WantedBy=multi-user.target <5>
----

Systemd is joyously simple to configure (especially if you've ever had the
dubious pleasure of writing an `init.d` script), and is fairly
self-explanatory. 

<1> `Restart=on-failure` will restart the process automatically if it crashes.

<2> `User=elspeth` makes the process run as the "elspeth" user.

<3> `WorkingDirectory` sets the working directory.

<4> `ExecStart` is the actual process to execute.  We use the `\ ` line
    continuation characters to split the full command over multiple lines,
    for readability, but it could all go on one line.

<5> `WantedBy` in the `[Install]` section is what tells Systemd we want this
    service to start on boot.


Systemd scripts live in '/etc/systemd/system', and their names must end in
'.service'. 

Now we tell Systemd to start Gunicorn with the `systemctl` command:

[role="server-commands"]
[subs="specialcharacters,quotes"]
----
# this command is necessary to tell Systemd to load our new config file
elspeth@server:$ *sudo systemctl daemon-reload*
# this command tells Systemd to always load our service on boot
elspeth@server:$ *sudo systemctl enable gunicorn-superlists-staging.ottg.eu*
# this command actually starts our service
elspeth@server:$ *sudo systemctl start gunicorn-superlists-staging.ottg.eu*
----

(you should find the `systemctl` command responds to tab-completion, including
of the service name, by the way)

Now we can rerun the FTs to see that everything still works. You can even test
that the site comes back up if you reboot the server!


.Debugging Tips
*******************************************************************************
Deployments are tricky!  If ever things don't go exactly as expected, here are
a few tips and things to look out for:
((("debugging", "Server deployment debugging tips")))

- I'm sure you already have, but double-check that each file is exactly where
  it should be and has the right contents--a single stray character can make
  all the difference.

- Nginx error logs go into '/var/log/nginx/error.log'.

- You can ask Nginx to "check" its config using the -t flag:

    nginx -t

- You can ask Ubuntu to check the validity of your init script with 
  http://manpages.ubuntu.com/manpages/precise/man8/init-checkconf.8.html[init-checkconf]

- Check the Systemd logs for using 
  `sudo journalctl -u gunicorn-superlists-staging.ottg.eu`

- Remember to restart both services whenever you make changes.

- If you make changes to the Systemd config file, you need to 
  run `daemon-reload` before `systemctl restart` to see the effect
  of your changes.

- Make sure your browser isn't caching an out-of-date response.  Use
  Ctrl+Refresh, or start a new private browser window.

- This may be clutching at straws, but I've sometimes seen inexplicable
  behaviour on the server that's only been resolved when I fully restarted it
  with a `sudo reboot`.

If you ever get completely stuck, there's always the option of blowing away
your server and starting again from scratch!  It should go faster the second
time...

*******************************************************************************


Saving Our Changes: Adding Gunicorn to Our requirements.txt
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Back in the 'local' copy of your repo, we should add Gunicorn to the list
of packages we need in our virtualenvs:

[subs="specialcharacters,quotes"]
----
$ *pip install gunicorn*
$ *pip freeze | grep gunicorn >> requirements.txt*
$ *git commit -am "Add gunicorn to virtualenv requirements"*
$ *git push* 
----
(((range="endofrange", startref="ix_deploymentprodready")))

NOTE: On Windows, at the time of writing, Gunicorn would pip install quite
    happily, but it wouldn't actually work if you tried to use it.  Thankfully
    we only ever run it on the server, so that's not a problem. And, Windows
    support is
    http://stackoverflow.com/questions/11087682/does-gunicorn-run-on-windows[being discussed]...



Automating
~~~~~~~~~~

((("deployment", "automating", id="ix_deployauto", range="startofrange")))
((("provisioning", "overview")))
((("deployment", "overview")))
Let's recap our provisioning and deployment procedures:

Provisioning::
1. Assume we have a user account and home folder
2. `add-apt-repository ppa:fkrull/deadsnakes`
2. `apt-get install nginx git python3.6 python3.6-venv`
3. Add Nginx config for virtual host
4. Add Systemd job for Gunicorn


Deployment::
1. Create directory structure in '~/sites'
2. Pull down source code into folder named 'source'
3. Start virtualenv in '../virtualenv'
4. `pip install -r requirements.txt`
5. `manage.py migrate` for database
6. `collectstatic` for static files
7. Set DEBUG = False and ALLOWED_HOSTS in 'settings.py'
8. Restart Gunicorn job
9. Run FTs to check everything works


Assuming we're not ready to entirely automate our provisioning process, how
should we save the results of our investigation so far?  I would say that 
the Nginx and Systemd config files should probably be saved somewhere, in
a way that makes it easy to reuse them later.  Let's save them in a new
subfolder in our repo:


[subs="specialcharacters,quotes"]
----
$ *mkdir deploy_tools*
----


[role="sourcecode"]
.deploy_tools/nginx.template.conf
[source,nginx]
----
server {
    listen 80;
    server_name SITENAME;

    location /static {
        alias /home/elspeth/sites/SITENAME/static;
    }

    location / {
        proxy_set_header Host $host;
        proxy_pass http://unix:/tmp/SITENAME.socket;
    }
}
----


[role="sourcecode"]
.deploy_tools/gunicorn-systemd.template.service
[source,bash]
----
[Unit]
Description=Gunicorn server for SITENAME

[Service]
Restart=on-failure
User=elspeth
WorkingDirectory=/home/elspeth/sites/SITENAME/source
ExecStart=/home/elspeth/sites/SITENAME/virtualenv/bin/gunicorn \
    --bind unix:/tmp/SITENAME.socket \
    superlists.wsgi:application

[Install]
WantedBy=multi-user.target
----

Then it's easy for us to use those two files to generate
a new site, by doing a find & replace on  `SITENAME`.

For the rest, just keeping a few notes is OK. Why not keep
them in a file in the repo too?

[role="sourcecode"]
.deploy_tools/provisioning_notes.md
[source,rst]
----
Provisioning a new site
=======================

## Required packages:

* nginx
* Python 3.6
* Git
* pip
* virtualenv

e.g.,, on Ubuntu:

    sudo add-apt-repository ppa:fkrull/deadsnakes
    sudo apt-get install nginx git python36 python3.6-venv

## Nginx Virtual Host config

* see nginx.template.conf
* replace SITENAME with, e.g., staging.my-domain.com

## Systemd service

* see gunicorn-systemd.template.service
* replace SITENAME with, e.g., staging.my-domain.com

## Folder structure:
Assume we have a user account at /home/username

/home/username
└── sites
    └── SITENAME
         ├── database
         ├── source
         ├── static
         └── virtualenv
----

We can do a commit for those:

[subs="specialcharacters,quotes"]
----
$ *git add deploy_tools*
$ *git status* # see three new files
$ *git commit -m "Notes and template config files for provisioning"*
----


(((range="endofrange", startref="ix_gunicorn")))
(((range="endofrange", startref="ix_deployauto")))
Our source tree will now look something like this:

----
$ tree -I __pycache__
.
├── deploy_tools
│   ├── gunicorn-systemd.template.service
│   ├── nginx.template.conf
│   └── provisioning_notes.md
├── functional_tests
│   ├── __init__.py
│   ├── [...]
├── lists
│   ├── __init__.py
│   ├── models.py
│   ├── static
│   │   ├── base.css
│   │   ├── [...]
│   ├── templates
│   │   ├── base.html
│   │   ├── [...]
├── manage.py
├── requirements.txt
└── superlists
    ├── [...]
----


.Test-Driving Server Configuration and Deployment 
*******************************************************************************

Tests take some of the uncertainty out of deployment::
    As developers, server administration is always "fun", by which I mean, a
    process full of uncertainty and surprises. My aim during this chapter was
    to show a functional test suite can take some of the uncertainty out of the
    process.  
    ((("deployment", "key points")))
    ((("server configuration")))

Typical pain points--database, static files, dependencies, custom settings::
    The things that you need to keep an eye out on any deployment include
    your database configuration, static files, software dependencies, and
    custom settings that differ between development and production.  You'll
    need to think through each of these for your own deployments.

Tests allow us to experiment::
    Whenever we make a change to our server configuration, we can rerun the
    test suite, and be confident that everything works as well as it did
    before.  It allows us to experiment with our setup with less fear.

*******************************************************************************

"Saving Your Progress"
^^^^^^^^^^^^^^^^^^^^^^

((("deployment", "saving progress")))
Being able to run our FTs against a staging server can be very reassuring.
But, in most cases, you don't want to run your FTs against your "real" server.
In order to "save our work", and reassure ourselves that the production server
will work just as well as the real server, we need to make our deployment
process repeatable.

Automation is the answer, and it's the topic of the next chapter.
(((range="endofrange", startref="ix_deptest")))

