[[hot-lava-chapter]]
Fast tests, slow tests and Hot Lava
-----------------------------------

[quote, 'https://www.youtube.com/watch?v=bsmFVb8guMU[Casey Kinsey]']
______________________________________________________________
The database is Hot Lava!
______________________________________________________________

Right up until <<isolation-chapter>>, almost all of the "unit" tests in
the book were integrated tests, because they either rely on the database, or
they use the Django Test Client, which does too much magic with the middleware
layers that sit between requests, responses and view functions.

There is an argument that an true unit test should always be isolated, because
it's meant to test a single unit of software.

TDD veterans say you should strive to write "pure", isolated unit tests
wherever possible, instead of writing integrated tests.  In this chapter, I'd
like to talk about why they say that, and try and give you some idea of when
you can get away with muddling through with integrated tests, and when it's
worth striving for more "pure" unit tests..


.Terminology: different types of test
******************************************************************************

Isolated tests ("pure" unit tests) vs integrated tests:: 
    The primary purpose of a unit test should be to verify the correctness
    of the logic of your application.  
    An *isolated* test is one that tests exactly one chunk of code, and whose
    success or failure does not depend on any other external code. This is what
    I call a "pure" unit test:  a test for a single function, for example,
    written in such a way that only that function can make it fail.  If the
    function depends on another system, and breaking that system breaks our
    test, we have an *integrated* test. That system could be an external
    system, like a database, but it could also be another function which we
    don't control.  In either case, if breaking the system makes our test fail,
    our test is not properly isolated, it is not a "pure" unit test.  That's
    not necessarily a bad thing, but it may mean the test is doing two jobs at
    once.

Integration tests::
    An integration test checks that the code you control is integrated
    correctly with some external system which you don't control. 
    'Integration' tests are typically also 'integrated' tests. 

System tests::
    If an integration test checks the integration with one external system,
    a system test checks the integration of multiple systems in your
    application -- for example, checking that we've wired up our database,
    static files, our server config, together in such a way that they all work.
    
Functional tests and Acceptance tests::
    An acceptance test is meant to test that our system works from the point
    of view of the user ("would the user accept this behaviour?").  It's 
    hard to write an acceptance test that's not a full-stack, end-to-end test.
    We've been using our functional tests to play the role of both acceptance
    tests and system tests.
    
******************************************************************************


WARNING: This chapter has reverted to draft format following the addition
    of a new chapter on tests isolation.  Apologies to readers, bullet points
    etc follow.



Why you might want tests to be fast fast fast
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Other things being equal, the faster your unit tests run, the better.  To a 
lesser extent, the faster 'all' your tests run, the better.


Faster tests mean faster development
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

I've outlined the TDD test/code cycle in this book.  You've started to get a 
feel for the TDD workflow, the way you flick between writing tiny amounts of
code, and running your tests.  You end up running your unit tests several times
a minute, and your functional tests several times a day. So, naturally, the
longer they take, the more time you spend waiting for your tests, and that 
will slow down your development.


Flow
^^^^

One of the great things about programming is getting into the "flow" state.
And one of the things that's likely to kick you out of that state is if your
tests start taking so long that you context-switch.


Slow tests don't get run as often, which causes bad code
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The follow-up argument is that, if your test suite is slow, then running it
becomes annoying.  As a developer, the danger is that you'll start to avoid
running your tests, which may lead to bugs getting through, or it may lead
to programmers being shy of refactoring the code, since they know that any
refactor will mean having to wait ages while all the tests run. In either
case, bad code can be the result.


We're fine now, but integrated tests get slower over time
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

So far, you might be thinking, OK, but our test suite has lots of integrated
tests in it - over 50 of them, and it only takes 0.2 seconds to run.

But remember, we've got a very simple app. Once your starts to get more
complex, as your database grows more and more tables and columns, integrated
tests will get slower and slower.  Having Django reset the database between
each test will take longer and longer.  

At PythonAnywhere, we have a "unit" test suite that's full of integrated tests,
and it now takes almost an hour to run.  Needless to say we don't run the whole
thing day-to-day, while developing.  


Don't take it from me
^^^^^^^^^^^^^^^^^^^^^

Gary Bernhardt, a man with far more experience of testing than me, put these
points eloquently in a talk called
https://www.youtube.com/watch?v=RAxiiRPHS9k[Fast Tests, Slow test]. I encourage
you to watch it.  


The problems with "pure" unit tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* harder to write
* harder to read
* don't test integration between components
* need to remember + think about both sides of "contracts"


What do we want from our tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* help verify correctness - at both the high level and low level
* encourage us to keep refactoring our code
* prevent regressions
* drive good design
* provide fast feedback.  want to know asap if we break something
* maintainable -- tests shouldn't be a major brake on efforts to
  evolve our application


Architectural solutions
~~~~~~~~~~~~~~~~~~~~~~~

So it sounds like, other things being equal, having more unit tests
and fewer integrated tests would help get us faster feedback cycles
and drive a better application design.  


This is sometimes described as trying to create a
http://watirmelon.com/tag/testing-pyramid/["testing pyramid"].


But how do we avoid the risk of our test suite becoming less reliable at
finding bugs, as we make it more isolated?


Ports and adapters / Hexagonal architecture
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Integrated tests are most useful at the 'boundaries' of a system -- at
the points where our code integrates with external systems, like a
database, filesystem, or UI components.

Conversely, code at the 'core' of our application -- code that's purely
concerned with our business domain and business rules, code that's 
entirely under our control -- this code has less need for integrated
tests, since we control and understand all of it.

So one way of getting what we want is to try and minimise the amount
of our code that has to deal with boundaries, test our core business
logic with isolated tests and test our integration points with integrated
tests.

Steve Freeman and Nat Pryce, in their book <<GOOSGBT, Growing Object-Oriented
Software, Guided By Tests>>, call this approach "Ports and Adapters" (see
<<ports-and-adapters>>).

[[ports-and-adapters]]
.Ports and Adapters (diagram by Nat Pryce)
image::images/ports-and-adapters-architecture.svg[Illustration of ports and adapaters architecture, with isolated core and integration points]

You can also see
http://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html[Uncle
Bob's perspective on his blog], and you should also have a look at 
http://alistair.cockburn.us/Hexagonal+architecture[Alistair Cockburn coining
the term Hexagonal Architecture] to describe this pattern.



Functional Core, Imperative Shell
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Gary Bernhard pushes this further, recommending an architecture he calls
"Functional Core, Imperative Shell", whereby the "shell" of the application,
the place where interaction with boundaries happens, follows the imperative
programming paradigm, and can be tested by integrated tests, acceptance tests,
or even (gasp!) not at all, if it's kept minimal enough. But the core of the
application is actually written following the functional programming paradigm
(complete with the "no side-effects" corollary), which actually allows fully
isolated, "pure" unit tests, 'entirely without mocks'.

Check out Gary's presentation titled
"https://www.youtube.com/watch?v=eOYal8elnZk[Boundaries]" for more on this
approach.


.Further reading
*******************************************************************************

Fast Test, Slow Test and Boudaries:: 
    Gary Bernhardt's talks from Pycon 2012
    https://www.youtube.com/watch?v=RAxiiRPHS9k and 
    2013: https://www.youtube.com/watch?v=eOYal8elnZk.  His screencasts at 
    http://www.destroyallsoftware.com are also well worth a look.

Ports and Adapters:: 
    Steve Freeman and Nat Pryce wrote about this in <<GOOSGBT, their book>>.
    You can also catch a good discussion of the idea in this talk:
    http://vimeo.com/83960706. There's also
    http://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html[Uncle
    Bob's blog], and 
    http://alistair.cockburn.us/Hexagonal+architecture[Alistair Cockburn's
    site].

Hot Lava::
    Casey Kinsey's memorable warning about avoiding the database whenever
    you can: https://www.youtube.com/watch?v=bsmFVb8guMU


Integrated tests are a scam::
    J.B. Rainsberger has a famous rant about the way integrated tests will
    ruin your life, http://blog.thecodewhisperer.com/2010/10/16/integrated-tests-are-a-scam/[here].
    Watch the video presentation 
    http://www.infoq.com/presentations/integration-tests-scam[here] or 
    http://vimeo.com/80533536[here] (there are two videos available choose,
    neither has perfect cinematography). Then check out a couple of 
    follow-up posts, particularly 
    http://www.jbrains.ca/permalink/using-integration-tests-mindfully-a-case-study[this
    defence of acceptance tests] (what I call functional tests), and
    http://www.jbrains.ca/permalink/part-2-some-hidden-costs-of-integration-tests[this
    analysis of how slow tests kill productivity]

Inverting the Pyramid::

    http://watirmelon.com/tag/testing-pyramid/

*******************************************************************************

