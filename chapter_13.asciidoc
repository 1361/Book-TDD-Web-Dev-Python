Database migrations
-------------------


NOTE: The book has been upgraded to Django 1.7 beta
overnight. If you started out on version 1.6, you
can upgrade using
+pip install --upgrade https://www.djangoproject.com/download/1.7b1/tarball/+.
Comments welcomed!

Since Django 1.7 came out, with its new migrations framework, migrations
are built in from the ground up, so there's no need to do anything special
when we deploy our code - the database will be migrated automatically.

This chapter is really just a guide for the ultra-cautious, in case you
want to test your migrations step by step.

TODO: make sure we've actually created the migration for data integrity
in the previous chapter!

Doing a trial run of the migration against our local database
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Let's test this out on our local PC first.  We need to make a database that has
the old state, ie one that looks like live.  We can use the tag we made
in our repository during the deploy.

[subs="specialcharacters,quotes"]
----
$ *git checkout LIVE*
$ *rm ../database/db.sqlite3*
$ *python3 manage.py migrate --noinput*
$ *git checkout master*
----

.If you didn't tag the release back when we deployed
******************************************************************************
You can use `git log` to look back for a commit that we made during 
<<deployment-chapter>>, or maybe right at the beginning of <<fabric-chapter>>.

[role="skipme"]
[subs="specialcharacters,quotes"]
----
$ *git log --oneline --decorate*
[...]
18480bd Create base FT class and a class for each test.
87e99b5 Moved functional tests into a folder.
7fa00f1 New ft for item validation.
8ca488b Add a fabfile for automated deploys    # <---  this looks like it!
d28e6ea Notes and template config files for provisioning
6b0d814 Add gunicorn to virtualenv requirements
6a6c91e Add requirements.txt for virtualenv
----

Note down that commit number and then use it to retrospectively add the tag:

[role="skipme"]
[subs="specialcharacters,quotes"]
----
$ *git tag LIVE 8ca488b*  # substitute in your own commit number!
----

Then you should be able to follow on with the instructions.
******************************************************************************


Adding some test data
^^^^^^^^^^^^^^^^^^^^^

Open up the site from `runserver` and enter a couple of lists. Make a note of
their URLs.


Running the migration
^^^^^^^^^^^^^^^^^^^^^

Running the migration is the usual `migrate` command:

[subs="specialcharacters,quotes"]
----
$ *python3 manage.py migrate --migrate*
----

Open up the `runserver` again and check our lists are still there... OK.


Testing the migration against staging
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

So how are we actually going to do this on our live servers?  As usual,
we start by using our staging server.

First we pushing up our latest changes so that we can pull them down on the
server:

[role="skipme"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*git push*]  
----

And deploy!

//TODO: unskip
[role="skipme"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*cd deploy_tools*]
$ pass:quotes[*fab deploy --host=superlists-staging.ottg.eu*]
[superlists-staging.ottg.eu] Executing task 'deploy'
[superlists-staging.ottg.eu] run: mkdir -p
/home/harry/sites/superlists-staging.ottg.eu
[...]
[superlists-staging.ottg.eu] run: /home/elspeth/sites/superlists-staging3.ottg.eu/source/../virtualenv/bin/pip install -r /home/elspeth/sites/superlists-staging3.ottg.eu/source/requirements.txt
[...]
[superlists-staging3.ottg.eu] out: Requirement already satisfied (use --upgrade to upgrade): gunicorn==18.0 in ./sites/superlists-staging3.ottg.eu/virtualenv/lib/python3.3/site-packages (from -r /home/elspeth/sites/superlists-staging3.ottg.eu/source/requirements.txt (line 2))
[...]
[superlists-staging3.ottg.eu] out: Downloading/unpacking South==0.8.3 (from -r /home/elspeth/sites/superlists-staging3.ottg.eu/source/requirements.txt (line 3))
[superlists-staging3.ottg.eu] out:   Downloading South-0.8.3-py2.py3-none-any.whl (135kB): 
[superlists-staging3.ottg.eu] out:   Downloading South-0.8.3-py2.py3-none-any.whl (135kB):   9%  12kB 
[...]
[superlists-staging3.ottg.eu] out: Successfully installed South
[...]
[superlists-staging.ottg.eu] run: cd
/home/harry/sites/superlists-staging.ottg.eu/source &&
../virtualenv/bin/python3 manage.py migrate
[superlists-staging.ottg.eu] out: Syncing...

[...]
[superlists-staging.ottg.eu] out: Synced:
[superlists-staging.ottg.eu] out:  > django.contrib.auth
[superlists-staging.ottg.eu] out:  > django.contrib.contenttypes
[...]
[superlists-staging.ottg.eu] out:  > functional_tests
[superlists-staging.ottg.eu] out:  > south
[superlists-staging.ottg.eu] out: 
[superlists-staging.ottg.eu] out: Not synced (use migrations):
[superlists-staging.ottg.eu] out:  - lists
[superlists-staging.ottg.eu] out: (use ./manage.py migrate to migrate these)
[superlists-staging.ottg.eu] out: 

[superlists-staging.ottg.eu] run: cd
/home/harry/sites/superlists-staging.ottg.eu/source &&
../virtualenv/bin/python3 manage.py migrate lists --fake 0001
[superlists-staging.ottg.eu] out:  - Soft matched migration 0001 to 0001_initial.
[superlists-staging.ottg.eu] out: Running migrations for lists:
[superlists-staging.ottg.eu] out:  - Migrating forwards to 0001_initial.
[superlists-staging.ottg.eu] out:  > lists:0001_initial
[superlists-staging.ottg.eu] out:    (faked)
[superlists-staging.ottg.eu] out: 
[superlists-staging.ottg.eu] run: cd
/home/harry/sites/superlists-staging.ottg.eu/source &&
../virtualenv/bin/python3 manage.py migrate
[superlists-staging.ottg.eu] out: Running migrations for lists:
[superlists-staging.ottg.eu] out:  - Migrating forwards to
0002_auto__add_unique_item_list_text.
[superlists-staging.ottg.eu] out:  > lists:0002_auto__add_unique_item_list_text
[superlists-staging.ottg.eu] out:  - Loading initial data for lists.
[superlists-staging.ottg.eu] out: Installed 0 object(s) from 0 fixture(s)
[superlists-staging.ottg.eu] out: 
----

Looks good.  We then go in and restart our web server:

[role="skipme"]
.server commands
----
user@server:$ sudo restart gunicorn-superlists-staging.ottg.eu 
----

.If your existing data violates the integrity constraint
******************************************************************************

If you see a message saying '"FATAL ERROR - The following SQL query
failed: CREATE UNIQUE INDEX..."', it could be that your existing data
violates the integrity constraint, ie you have some duplicate items already
in the database.  

At this point, the thing to do will be to create a 
`data migration` script which goes through, detects any data integrity
problems in the old data, and assigns some dummy values to save them.

Further discussion is outside the scope of the book, but check out
https://docs.djangoproject.com/en/dev/topics/migrations/#data-migrations[the
docs].

And think how glad you feel that your staging server caught this, rather
than your live server!

******************************************************************************


Running the FT to confirm the migration has worked
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

And we can now run our FTs against staging:

[role="skipme"]
----
$ python3 manage.py test functional_tests --liveserver=superlists-staging.ottg.eu
Creating test database for alias 'default'...
....
 ---------------------------------------------------------------------
Ran 4 tests in 17.308s

OK
----


Applying the migration to live
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Everything seems in order!  Let's do it against live:


[role="skipme"]
[subs="specialcharacters,macros"]
----
$ pass:quotes[*cd deploy_tools*]
$ pass:quotes[*fab deploy --host=superlists.ottg.eu*]
[superlists.ottg.eu] Executing task 'deploy'

[...]
----

You'll need to restart the live gunicorn job too.


Wrap-up: git tag the new release
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

And finally we tag our latest release:

[subs="specialcharacters,quotes"]
----
$ *git tag -f LIVE*  # needs the -f because we are replacing the old tag
$ *export TAG=`date +DEPLOYED-%F/%H%M`*
$ *git tag $TAG*
$ *git push -f origin LIVE $TAG*
----

Conclusions
~~~~~~~~~~~

We've now tested out our migration locally, and we've run it once on the
staging site.  We've tested that our application still works after the
migration, both locally and on staging, using our functional test suite. 
We're comfortable that we can modify our database schema. Is there anything
else we need to do?

You might worry that the most dangerous thing about a migration isn't so much
that we can adjust our database schema, but more that we might lose data during
the change.  Shouldn't we somehow test that the existing data in the database
is still there after we migrate?

The answer to that is: you should if you're 'particularly' nervous.  Hopefully
you've now got enough building blocks from this book to see how you might be 
able to write some automated tests that would do just that.


.On testing database migrations
******************************************************************************

Don't test third party code::
    One of the rules of thumb in testing is "don't test third party code".  If
    you're using some kind of external library, you can't afford to spend your
    time writing tests for their code as well as your own -- you just have to
    decide whether you trust them or not.  South is an incredibly popular tool,
    it's been around for ages, and we can be pretty confident that it's going
    to do what it says it does.


Do test migrations for speed::
    One thing you should be testing is how long your migrations are going to
    take. Database migrations typically involve down-time, as, depending on
    your database, the schema update operation may lock the table it's working
    on until it completes.  It's a good idea to use your staging site to find
    out how long a migration will take.


Be extremely careful if using a dump of production data::
    In order to do so, you'll want fill your staging site's database with an
    amount of data that's commensurate to the size of your production data.
    Explaining how to do that is outside of the scope of this book, but I will
    say this:  if you're tempted to just take a dump of your production
    database and load it into staging, be 'very' careful.  Production data
    contains real customer details, and I've personally been responsible for
    accidentally sending out a few hundred incorrect invoices after an
    automated process on my staging server started processing the copied
    production data I'd just loaded into it. Not a fun afternoon.

******************************************************************************


And on that stern note, time to move on to the next chapter!  Hopefully it'll
have something fun in it to cheer us up.  Oh, wait --

