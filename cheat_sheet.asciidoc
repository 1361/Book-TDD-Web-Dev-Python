Cheat Sheet
-----------

Initial project setup
~~~~~~~~~~~~~~~~~~~~~

* Start with a 'User Story' and map it to a first Functional Test

* Pick a test framework -- `unittest` is fine, options like `py.test`
  and `nose` can also offer some attributes

* Run the Functional Test and see your first 'expected failure'

* Pick a web framework such as Django, and find out how to run
  'unit tests' against it.

* Create your first 'unit test' to address the current FT failure,,
  and see it fail.

* Consider doing your 'first commit' to a VCS like 'Git'.

Relevant chapters: 1, 2, 3


The TDD workflow
----------------

* Double-loop TDD

* Red, Green, Refactor

* Trianglulation

* The scratchpad

* "3 Strikes and Refactor"

* "Working State to Working State"

* "YAGNI"

Chapters 5, 6


[[Double-Loop-TDD-diagram]]
.The TDD process with Functional and Unit tests
image::images/twdp_0404.png[A flowchart showing functional tests as the overall cycle, and unit tests helping to code]



Moving beyond dev-only testing
------------------------------

* Start system testing early

* Ensure your components work together: web server, static content, database

* Build a staging environment to match your production environment

* Run your FT suite against staging

* Automate your staging and production environments:
    * PaaS vs VPS
    * Fabric
    * Configuration management (Chef, Puppett, Salt, Ansible...)
    * Vagrant

* Think through deployment pain points


Testing best practices
-----------------------

* Each test should test one thing
* One tests file per application code source file
* Thin views
* Consider a placeholder test for every function and class
* "Don't test constants"
* Try to test behaviour rather than implementation
* Testing templates: consider testing any ifs or fors -- using
  your FTs for this may be fine, but some lower-level tests may
  give you faster feedback
* Testing input validation -- test error cases thoroughly.



== chapter_13 


== chapter_14 


.JavaScript testing notes
*******************************************************************************

* One of the great advantages of Selenium is that it allows you to test that
  your JavaScript really works, just as it tests your Python code.

* There are many JavaScript test running libraries out there.  Qunit is closely
  tied to jQuery, which is the main reason I chose it.  

* Qunit mainly expects you to "run" your tests using an actual web browser.
  This has the advantage that it's easy to create some HTML fixtures that 
  match the kind of HTML your site actually contains, for tests to run against.

* I don't really mean it when I say that JavaScript is awful. It can actually
  be quite fun.  But I'll say it again: make sure you've read
  <<jsgoodparts,JavaScript: The Good Parts>>.

*******************************************************************************


== chapter_15 

.On Spiking and Mocking with JavaScript
*******************************************************************************
Spiking::
    Exploratory coding to find out about a new API, or to explore the
    feasibility   of a new solution.  Spiking can be done without tests.  It's
    a good idea to do your spike on a new branch, and go back to master when
    de-spiking.

Mocking::
    We use mocking in unit tests when we have an external dependency that we
    don't want to actually use in our tests.  A mock is used to simulate the 
    3rd party API.   Whilst it is possible to "roll your own" mocks in
    JavaScript, a mocking framework like Sinon.js provides a lot of helpful
    shortcuts which will make it easier to write (and more importantly, read)
    your tests.

Unit testing Ajax::
    Sinon.js is a great help here. Manually mocking Ajax methods is a real
    pain.

*******************************************************************************


== chapter_16 

.On Mocking in Python
*******************************************************************************

The Mock library::
    Michael Foord (who used to work for the company that spawned
    PythonAnywhere, just before I joined) wrote the excellent "Mock"
    library that's now been integrated into the standard library of Python 3.
    It contains most everything you might need for mocking in Python

The patch decorator::
    `unittest.mock` provides a function called `patch`, which can be used
    to "mock out" any object from the module you're testing.  It's commonly
    used as a decorator on a test method, or even at the class level, where
    it's applied to all the test methods of that class

Mocks are truthy and can mask error::
    Be aware that mocking things out can cause counter-intuitive behaviour
    in `if` statements.  Mocks are truthy, and they can also mask errors,
    because they have all attributes and methods.

Mocking the Django ORM::
    If you want to avoid "touching" the database in your tests, you can
    use Mock to simulate the Django ORM.  I tend to think that's more trouble
    than it's worth. See the "Hot Lava" appendix for more discussion.

Too many mocks are a code smell::
    Overly mocky tests end up very tightly coupled to their implementation.
    Sometimes this is unavoidable.  But, in general, try to find ways
    of organising your code so that you don't need too many mocks.

*******************************************************************************


== chapter_17 

.Fixtures and logging
*******************************************************************************

De-duplicate your FTs, with caution::
    Every single FT doesn't need to test every single part of your application.
    In our case, we wanted to avoid going through the full log-in process for
    every FT that needs an authenticated user, so we used a test fixture to 
    "cheat" and skip that part. You might find other things you want to skip 
    in your FTs.  A word of caution however: functional tests are there to 
    catch unpredictable interactions between different parts of your
    application, so be wary of pushing de-duplication to the extreme.
    
Test fixtures::
    Test fixtures refers to test data that needs to be set up as a precondition
    before a test is run -- often this means populating the database with some
    information, but as we've seen (with browser cookies), it can involve other
    types of preconditions.

Avoid JSON fixtures::
    Django makes it easy to save and restore data from the database in JSON
    format (and others) using the `dumpdata` and `loaddata` management
    commands.  Most people recommend against using these for test fixtures,
    as they are painful to manage when your database schema changes. Use the
    ORM, or a tool like https://factoryboy.readthedocs.org/[factory_boy].

Fixtures also have to work remotely::
    `LiveServerTestCase` makes it easy to interact with the test database 
    using the Django ORM for tests running locally.  Interacting with the 
    database on the staging server is not so straightforward -- one solution
    is Django management commands, as I've shown, but you should explore what
    works for you, and be careful!

Use loggers named after the module you're in::
    The root logger is a single global object, available to any library that's
    loaded in your Python process, so you're never quite in control of it. 
    Instead, follow the `logging.getLogger(__name__)` pattern to get one that's
    unique to your module, but that inherits from a top-level configuration you
    control

Test important log messages::
    As we saw, log messages can be critical to debugging issues in production.
    If a log message is important enough to keep in your codebase, it's
    probably important enough to test.  We follow the rule of thumb that
    anything above `logging.INFO` definitely needs a test.  Using
    `patch.object` on the logger for the module you're testing is one
    convenient way of unit testing it.

*******************************************************************************


== chapter_18 


.Outside-In TDD
*******************************************************************************

Outside-in TDD::
    A methodology for building code, driven by tests, which proceeds by
    starting from the "outside" layers (presentation, GUI), and moving
    "inwards" step-by-step, via view/controller layers, down towards 
    the model layer.  The idea is to drive the design of your code from
    the use to which it is going to be put, rather than trying to anticipate
    requirements from the ground up.

Programming by wishful thinking::
    The outside-in process is sometimes called "programming by wishful
    thinking".  Actually, any kind of TDD involves some wishful thinking. 
    We're always writing tests for things that don't exist yet.

The pitfalls of outside-in::
    Outside-In isn't a silver bullet.  It encourages us to focus on things
    that are immediately visible to the user, but it won't automatically 
    remind us to write other critical tests that are less user-visible; 
    things like security for example. You'll need to remember them yourself.

*******************************************************************************


== chapter_19 

.On the pros and cons of different types of test, and decoupling ORM code
*******************************************************************************

Functional tests::
    * Provide the best guarantee that your application really works correctly,
    from the point of view of the user.
    * But: it's a slower feedback cycle,
    * And they don't necessarily help you write clean code.

Integrated tests (reliant on, eg, the ORM or the Django Test Client)::
    * Are quick to write,
    * Easy to understand,
    * Will warn you of any integration issues,
    * But may not always drive good design (that's up to you!).
    * And are usually slower than isolated tests

Isolated ("mocky") tests::
    * These involve the most hard work.
    * They can be harder to read and understand,
    * But: these are the best ones for guiding you towards better design.
    * And they run the fastest.

Decoupling our application from ORM code::
    When striving to write isolated tests, one of the consequences is that we
    find ourselves forced to remove ORM code from places like views and forms,
    by hiding it behind helper functions or methods.  This can be beneficial in
    terms of decoupling your application from the ORM, but also just because it
    makes your code more readable. As with all things, it's a judgement call as
    to whether the additional effort is worth it in particular circumstances.

*******************************************************************************


== chapter_20 

.Tips on CI and Selenium best practices
*******************************************************************************

Set up CI as soon as possible for your project::
    As soon as your functional tests take more than a few seconds to run,
    you'll find yourself avoiding running them all. Give this job to a CI
    server, to make sure that all your tests are getting run somewhere.

Set up screenshots and HTML dumps for failures::
    Debugging test failures is easier if you can see what the page looked
    at when the failure occurs.  This is particularly useful for debugging
    CI failures, but it's also very useful for tests that you run locally.

Use waits in Selenium tests::
    Selenium's `implicitly_wait` only applies to uses of its `find_element` 
    functions, and even that can be unreliable (it can find an element that's
    still on the old page).  Build a `wait_for` helper function, and alternate
    between actions on the site, and then some sort of wait to see that they've
    taken effect.

Look in to hooking up CI and staging::
    Tests against that use LiveServerTestCase are all very well for dev boxes,
    but the true reassurance comes from running your tests against a real 
    server.  Look into getting your CI server to deploy to your stagin server,
    and run the functional tests against that instead.  It has the side benefit
    of testing your automated deploy scripts.

*******************************************************************************


== chapter_21 

.The Page pattern, and the real exercise for the reader
*******************************************************************************

Apply DRY to your functional tests::
    Once your FT suite starts to grow, you'll find that different tests will
    inevitably find themselves using similar parts of the UI. Try to avoid 
    having constants, like the HTML IDs or classes of particular UI elements
    duplicated between your FTs.

The Page pattern::
    Moving helper methods into a base `FunctionalTest` class can become 
    unwieldy.  Consider using individual Page objects to hold all the
    logic for dealing with particular parts of your site. 

An exercise for the reader::
    I hope you've actually tried this out!  Try to follow the "Outside-In"
    method, and occasionally try things out manually if you get stuck. 
    The real exercise for the reader, of course, is to apply TDD to your
    next project.  I hope you'll enjoy it!

*******************************************************************************


== chapter_22 

.Further reading
*******************************************************************************

Fast Test, Slow Test and Boudaries:: 
    Gary Bernhardt's talks from Pycon 2012
    https://www.youtube.com/watch?v=RAxiiRPHS9k and 
    2013: https://www.youtube.com/watch?v=eOYal8elnZk.  His screencasts at 
    http://www.destroyallsoftware.com are also well worth a look.

Ports and Adapters:: 
    Steve Freeman and Nat Pryce wrote about this in <<GOOSGBT, their book>>.
    You can also catch a good discussion of the idea in this talk:
    http://vimeo.com/83960706. There's also
    http://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html[Uncle
    Bob's blog], and 
    http://alistair.cockburn.us/Hexagonal+architecture[Alistair Cockburn's
    site].

Hot Lava::
    Casey Kinsey's memorable warning about avoiding the database whenever
    you can: https://www.youtube.com/watch?v=bsmFVb8guMU

Inverting the Pyramid::
    The idea that projects end up with too great a ratio of slow, high-level
    tests to unit tests, and a visual metaphor for the effort to invert that
    ratio: http://watirmelon.com/tag/testing-pyramid/

Integrated tests are a scam::
    J.B. Rainsberger has a famous rant about the way integrated tests will
    ruin your life, http://blog.thecodewhisperer.com/2010/10/16/integrated-tests-are-a-scam/[here].
    Watch the video presentation 
    http://www.infoq.com/presentations/integration-tests-scam[here] or 
    http://vimeo.com/80533536[here] (there are two videos available choose,
    neither has perfect cinematography). Then check out a couple of 
    follow-up posts, particularly 
    http://www.jbrains.ca/permalink/using-integration-tests-mindfully-a-case-study[this
    defence of acceptance tests] (what I call functional tests), and
    http://www.jbrains.ca/permalink/part-2-some-hidden-costs-of-integration-tests[this
    analysis of how slow tests kill productivity]

*******************************************************************************

